\documentclass{article}
\usepackage{xcolor}
\usepackage[colorlinks=true, linkcolor=blue, citecolor=blue]{hyperref}
\usepackage[backend=bibtex,backref=true,hyperref=true]{biblatex}
\addbibresource{proportionality.bib}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{bbm}
\usepackage{fullpage}
\usepackage{setspace}
\usepackage{placeins}
\usepackage{color}

\usepackage{amsthm}
 
\theoremstyle{definition}
\newtheorem{definition}{Definition}

\definecolor{light-gray}{gray}{0.7}

\doublespacing

\title{RNA-Seq as a Relative Abundance Measure: oportunities afforded by a compositional analysis framework.}
\author{Dominic LaRoche \and Dean Billheimer \and Shripad Sinari \and Kurt Michels \and  Bonnie LaFleur}
\begin{document}

\maketitle

\doublespacing
% \section{Abstract}


\section{Introduction}

%-- Introduce the problem and motivate the research -->
% The rapid rise in the use of RNA sequencing technology (RNA-seq) for scientific discovery has led to its consideration as a clinical diagnostic tool. However, as a new technology, the analytical accuracy and reproducibility of RNA-seq must be established before it can realize its full clinical utility~\cite{SEQC/MAQC-IIIConsortium2014,VanKeuren-Jensen2014}. Recent studies evaluating RNA-seq have found generally high intra-platform and inter-platform congruence across multiple laboratories~\cite{Li2013, tHoen2013, SEQC/MAQC-IIIConsortium2014}. Despite these promising results, there remains a need to establish reliable diagnostics and quality control metrics to improve the reproducibility of RNA-seq data.  Understanding, and capatilizing on, the relative frequency nature of RNA-Seq data provides tools for  creating quality control metrics and identifying batch effects leading to improved reproducibility.\\

We develop quality control diagnostics for targeted RNA-Seq using the theory of compositional data.  Targeted sequencing allows researchers to efficiently measure transcripts of interest for a particular disease by focusing sequencing efforts on a select subset of transcript targets.  Targeted sequencing offers several benefits over traditional whole-transciptome RNA-Seq for clinical use including the elminiation of amplification bias, reduced sequencing cost, and a simplified bioinformatics workflow.  Moreover, extraction-free targeted sequencing technologies, such as HTG EdgeSeq, permit the use of very small sample volumes. However, extraction free technologies create the need for post-sequencing quality control metrics since poor quality samples, which would likely be removed after unsucessful RNA extraction in extraction-based technologies, can still be sequenced.  The post-sequencing methods described here should be easily extensible to traditional extraction-based RNA-Seq because targeted and traditional RNA-Seq data share many of the same properties.\\


%-- Brief intro to compositional data
Relative frequency measures are characterized as a vector of proportions of some whole.  These proportions are necessarily positive and sum to a constant which is determined by the measurement system and not the measurand.  
Targeted and whole transcriptome RNA-Seq measurements from NGS-based instruments provide only relative frequencies of the measured transcripts.  The measurment technology, along with sample preparation, preclude the measurement of absolute abundance. The total number of reads in a sequencing run for high-throughput RNA-Seq instruments is determined by the maximum number of reads available per run and not the absolute number of reads in a sample.  For example, the Illumina Mi-Seq is limited to 25 million reads in a sequencning run while the Roche 454 GS Junior \textsuperscript{(TM)}, with longer read lengths, claims approximately 100,000 reads per run for shotgun sequencing.  These reads are distributed across all of the samples included in a sequencing run and, therefore, impose a total sum constraint on the data.  This constraint cascades down to each probe or tag within a sample which is, in turn, constrained by the total number of reads allocated to the sample thereby creating a natural hierarchical structure to RNA-Seq data.\\

Previous authors have identified the relative abundance nature of RNA-Seq data~\cite{Robinson2007, Anders2010, Robinson2010, Law2014, Lovell2015}.  For example, Robinson and Smyth (2007)~\cite{Robinson2007} consider counts of RNA tags as relative abundances in their development of a model for estimating differential gene expression implemented in the Bioconductor package edgeR.  Similarly, Robinson and Oshlack (2010) explicitly acknowledge the mapped-read constraint when developing their widely used Trimmed-Mean of M-values (TMM) normalization method for RNA-Seq data. Finally, the commonly used log$_2$ Counts per Million (CPM) re-scaling transformation proposed by Law et al. (2014)~\cite{Law2014} divides each sequence count by the total number of reads allocated to the sample thereby transforming the data for each sample into a vector of proportions. \\%However, none of these authors reference the large body of literature on the analysis of compositions.


The positivity and summation constraint complicate the analysis of relative frequency data.  As early as 1896 Karl Pearson~\cite{Pearson1896} identified the spurious correlation problem associated with compositions.  John Aitchison observed that relative frequency data is compositional and developed a methodology based on the geometric constraints of composiitons~\cite{Aitchison1986}.  Recent authors have argued that ignoring the sum constraint can lead to unexpected results and erroneous inference~\cite{Lovell2011}.  Despite the evidence that RNA-Seq data are compositional in nature, few researchers have extended the broad set of compositional data analysis theory and operations for use in RNA-Seq analysis problems.  

We provide a brief background on compositional methods.  We then extend existing compositional data methodology to develop two quality control metrics and improve batch effect detection for RNA-Seq data. Finally, we show how compositional properties can be exploited to facilitate exploration of high-dimensional RNA-Seq data.\\

%-- Describe sequencing QC metrics a little
% Illumina incorporates several sequencing specific quality control metrics including percentage of clusters passing filters and cluster density analysis. Other quality control metrics are also available, such as HTQC~\cite{Yang2013}.  However, most of the quality control metrics, while informative, are subjective...  %not sure what to say about these

%Targeted sequencing vs traditional sequencing 


\section{Methods}

\subsection{Compositional Data}
%-- CODA intro -->
We begin with a brief introduction to compositional data, its properties, and some established analytical methods.  Compositional data is defined as any data in which all elements are non-negative and sum to a fixed constant~\cite{Aitchison1986}. %-- Establish notation  and data hierarchy-->
For RNA-seq data, the total sum constraint is imposed by the limited number of available reads in each sequencing run.  Since this total differs between sequencing platforms we will refer to the total number of available reads as $\mathbb{T}$. These reads are distributed among the $D$ samples in a sequencing run such that:
\begin{equation}
\sum_{i=1}^{D} t_i = \mathbb{T}
\label{sumt}
\end{equation}
where $t_i$ represents the total reads for sample $i$.  Because of the total sum constraint, the vector $\mathbf{t}$ is completely determined by $D-1$ elements since the $D^{th}$ element of $\mathbf{t}$ can be determined from the other $d = D-1$ elements and the total $\mathbb{T}$:  
\begin{equation}
t_D = \mathbb{T} - \sum_{i=1}^{d} \mathbf{t_i}
\label{sumConst}
\end{equation}
In \ref{sumConst}, any of the elements can be chosen for $t_D$ with the remaining elements labeled $1, ..., d$ in any order~\cite{Aitchison1986}.  Similarly, the total reads for each sample ($t_i$) are distributed among the $P$ transcript targets in the assay such that $\sum_{j=1}^{P} p_{ij} = t_i$, where $p_{ij}$ is the total reads allocated to target $j$ in sample $i$.  We highlight the hierarchichal structure of RNA-Seq data as it leads to useful properties when devloping quality control metrics.\\


From equations~\ref{sumt} and~\ref{sumConst} it is clear that the total reads allocated to each of the $D$ samples represent a $D - 1 = d$ dimensional simplex ($\mathcal{S}^d$). This leads to problems when using methods developed for standard Euclidean sample spaces such as interpreting the traditional $D \times D$ covariance structur or measuring the distance between vectors.  In particular, it is clear that for a D-part composition $\mathbf{x}$, $\text{cov}(x_1, x_1+ \cdots +x_D) = 0$  since $x_1 + \cdots + x_D$ is a constant.  Moreover, the sum constraint induces negativity in the covariance matrix,

\begin{equation}
\text{cov}(x_1, x_2) + \cdots + \text{cov}(x_1, x_D) = -\text{var}(x_1).
\label{negbias}
\end{equation}

Equation~\ref{negbias} shows that at least one element of each row of the covariance matrix must be negative. Aitchison refers to this as the ``negative bias difficulty" (although `bias' is not used in the traditional sense;~\cite{Aitchison1986}, p. 53). The structurally induced negative values create problems for the interpretation of the covariance matrix.  Similarly, the use of naive distance metrics in the simplex may not be interpretable as in Euclidean space. Because of these difficulties, standard statistical methodology is not always appropriate~\cite{Aitchison1986} and can produce misleading results~\cite{Lovell2015}.\\


  To overcome these obstacles, Aitchison~\cite{Aitchison1980} proposed working in ratios of components. We focus on the Centered Log-Ratio (CLR) which treats the parts of the composition symmetrically and provides an informative covariance structure.  The CLR transformation is defined for a $D$-part composition $\mathbf{x}$ as:
\begin{equation}
y_i  = \text{CLR}(x_i) = log \left(\frac{x_i}{g(\mathbf{x})} \right),
\label{clr}
\end{equation}

where $g(\mathbf{x})$ is the geometric mean of $\mathbf{x}$.  The $D \times D$ covariance matrix is then defined as:

\begin{equation}
\Gamma = \left[\text{cov}\left(y_i, y_j \right): i,\ j = 1, ..., D \right]
\label{gamma}
\end{equation}
\\

The CLR transformation is similar to the familiar Counts per Million (CPM) transformation~\cite{Law2014} defined as, $log_2 \left(\frac{r_{gi}+0.5}{t_i+1} \times 10^6 \right)$, where $r_{gi}$ is the number of sequence reads for each probe ($g$) and sample ($i$), (scaled to avoid zero counts), adjusted for the number of mapped reads (library count) for each sample $t_i$ (scaled by a constant 1 to ensure the proportional read to library size ratio is greater than zero). The primary difference between the CLR and log(CPM) transformations is in the use of the geomtric mean in the denominator of the CLR transformation. The use of the geometric mean results in subtracting the mean of the log transformed values from each element thereby centering the vector of log-ratio transformed read counts. The difference appears minor but has important implications for the application of several common statistical methods.\\


%%%Need to add in ALR transformation for compositional invariance section
Although the CLR transformation preserves the original dimmension of the data, and gives equal treatment to every element of $\mathbf{x}$, the resulting covariance matrix, $\Gamma$, is singular.  Therefore, care should be taken when using general multivariate methods on CLR transformed data. Aitchison~\cite{Aitchison1986} proposed an alternative transformation, the additive log-ratio (ALR), which does not treat the components symmetrically but results in a non-sigular covariance matrix.

\begin{equation}
y_i  = \text{ALR}(x_i) = log \left(\frac{x_i}{x_D} \right),
\label{alr}
\end{equation}

The ALR transformation 

The compositional geometry must be accounted for when measuring the distance between two compositions or finding the center of a group of compositions~\cite{Aitchison2000}.  Aitchison~\cite{Aitchison1992} outlined several properties for any compositional difference metric which must be met: scale invariance, permutation invariance, perturbation invariance (similar to translation invariance for Euclidean distance), and subcompositional dominance (similar to subspace dominance of Euclidean distance).  The scale invariance requirement is ignorable if the difference metric is applied to data on the same scale (which is generally not satisfied in raw RNA-seq data due to differences in read depth). The permutation invariance is generally satisfied by existing methods such as Euclidean distance~\cite{Martin-Fernandez1998}. However, the perturbation invariance and subcompositional dominance are not generally satisfied~\cite{Martin-Fernandez1998}. \\

Aitchison~\cite{Aitchison1986, Aitchison1992} suggests using the sum of squares of all log-ratio differences.  Billheimer, Guttorp, and Fagan~\cite{Billheimer2001} use the geometry of compositions to define a norm which, along with the perturbation operator defined by Aitchison~\cite{Aitchison1986}, allow the interpretation of differences in compositions. Martin-Fernandez et al.~\cite{Martin-Fernandez1998} showed that applying either Euclidean distance or Mahalanobis distance metric to CLR transformed data satisfies all the requirements of a compositional distance metric. Euclidean distance on CLR transformed compositions is referred to as Aitchison distance:

$$d_A(x_i, x_j) = \left[\sum_{k=1}^D \left( log \left(\frac{x_{ik}}{g(x_i)} \right) - log \left(\frac{x_{jk}}{g(x_j)} \right) \right)^2  \right]^\frac{1}{2}$$

or

 $$d_A(x_i, x_j) = \left[\sum_{k=1}^D \left( clr(x_{ik}) - clr(x_{jk}) \right)^2  \right]^\frac{1}{2}.$$
\\


To avoid numerical difficulties arising from sequence targets with 0 reads, Martin-Fernandez et al. (2000)~\cite{Martin-Fernandez2000} suggest an additive-multiplicative hybrid transformation.  If zeros are present in the data We recommend using the Martin-Fernandez transformation with a threshold value of $\delta = \frac{0.55}{\text{Total Reads}}$ to account for differences in sequencing depth.  The CLR transformation is then applied to the Martin-Fernandez transformed data which contains no zeros. \\




Up to this point we have referred to the total reads available per sequencing run, $\mathbb{T}$.  However, it is more typical to work with the aligned reads in practice.  The total aligned reads, $T$, is always a fraction of the total reads available for a sequencing run, $\mathbb{T}$.  The fraction of the total reads aligned can be a affected by multiple factors, including the choice of alignment algorithm, which we do not address here.  We assume that $T$ imposes the same constraints on the data as oultined above for $\mathbb{T}$ and will refer exclusively to $T$ hereafter.\\  


\section{Sample Quality Control}
Problems with sample quality, library preparation, or sequencing may result in a low number of reads allocated to a given sample within a sequencing run.  The Percent Pass Filter (\% PF) metric provided on Illumina sequencers provides a subjective measure that can identify problems with sequencing that result in a low number of reads allocated to a sample.  However, \% PF will not necessarily catch problems associated with poor sample quality or problems with sample pre-processing since these processes may affect cluster generation, and not just cluster quality.  This is particularly important for extraction-free RNA-Seq technologies, such as the HTG EdgeSeq$^{(tm)}$, which allow for the use of smaller input amounts but lack the intermediate steps for checking sample quality.  There is currently no objective way to evaluate sample quality based on the total number of reads attributed to a sample. We propose a method for objectively identifying problematic samples based on the total number of reads allocated to the sample. \\

For most experimental designs we expect the number of reads allocated to each sample in a sequencing run to arise from the same general data generating mechanism, namely the chemistry of the NGS-based measurement system, regardless of experimental condition.  The objective is then to determine which samples arise from a different mechanism.  Outlier detection is well suited for discovering obervations that deviate so much from other observations that they are likely to have arisen from a different mechanism~\cite{Hawkins1980}.  We base our method off Tukey's box-plots~\cite{Tukey1977}, which is a commonly used and robust method for detecting outliers~\cite{Ben-Gal2009}.\\

We expect the total number of reads allocated to each sample, $t_i$, to be equivalent notwithstanding random variation. For a given sequencing run with $D$ samples we define the vector of total reads allocated to each sample as $\mathbf{t}$.  Since the $D$ dimensional vector $\mathbf{t}$ is a composition we have $\mathbf{t} \in \mathcal{S}^{D-1}$, the $D-1$-dimensional simplex. As noted above, traditional statistical methods may not be appropriate for data in the simplex.  Therefore, we map $\mathbf{t} \in \mathcal{S}^{D-1} \rightarrow \mathbf{x} = CLR(\mathbf{t}) \in \mathcal{R}^D$ using the Centered Log Ratio transformation~\ref{clr}.  We then apply Tukey's method for detecting outliers to $\mathbf{x}$, which simply identifies those observations which lie outside 1.5 times the inter-quartile range.

\theoremstyle{definition}
\begin{definition}
$x_i$ is a quality control sample failure if $x_i <$ lower-quartile$- 1.5 \times$ IQR \emph{or}  $x_i >$ upper-quartile$+ 1.5 \times$ IQR, where IQR is the interquartile range of $\mathbf{x}$.
\end{definition}

We demonstrate the utility of our sample quality control measure using two sets of targeted RNA-Seq data: 1) 120 mRNA technical replicate universal-RNA samples prepared with the HTG EdgeSeq Immuno-Oncology assay and sequenced in 5 different equally sized runs, and 2) 105 miRNA technical replicate samples of human plasma, FFPE tissue, and Brain RNA prepared with the HTG EdgeSeq Whole Transcriptome miRNA assay.  These two data sets differ in the both the type of RNA (mRNA versus miRNA) and the number of sequence targets in each assay (558 versus 2,280 targets, for the mRNA and miRNA assays respectively).  All samples were prepared for sequencing using the HTG EdgeSeq Processor and sequenced with an Illumina Mi-Seq sequencer.\\

We compare the utility of our method to evaluation of the untransformed total counts.  Figure~\ref{totalFig} shows a boxplot and heatmap of the total number of reads allocated to each sample for each of 5 sequencing runs.  Figure~\ref{clrFig} shows the same data after CLR transformation.  After transformation the poor samples become much more visually evident in the heat maps.  Additionally, the ability to detect outlying values increases and the number of poor samples detected increases from 1 to 6.  \\
\textcolor{blue}{how would we demonstrate the increase in power mathematically?}

\begin{figure}
\includegraphics[scale=.5]{./Figures/IO_Repro_Combined_RawTotals}
\caption{A) Distributions of total reads allocated to each sample in 5 runs on an Illumina Mi-Seq sequencer. Only 1 sample is identified as a problematic sample. B) Heatmaps showing the relative totals for each sample within each run.  The darker heatmaps for runs 4 and 5 reflect the generally lower number of total reads in those sequencing runs as compared to runs 1 and 2.  This is caused by normal variation in the number of reads available in a sequencing run.}
\label{totalFig}
\end{figure}
 
\begin{figure}
\includegraphics[scale=.5]{./Figures/IO_Repro_Combined_CLR}
\caption{A) Distributions of CLR tranformed total reads allocated to each sample in 5 runs on an Illumina Mi-Seq sequencer. After CLR transformation, 6 samples are identified as a problematic. B) Heatmaps showing the relative CLR transformed totals for each sample within each run.}
\label{clrFig}
\end{figure}

\FloatBarrier
\section{Testing for Compositional Invariance}

Normalization and standardization methods for RNA-Seq generally assume that the total number of reads assigned to a sample does not affect the observed relative frequencies of probes within an assay.  For example, implicit in the CPM transformation is the idea that if you re-scale the counts (by dividing by the total for each sample) then the resulting counts are comparible and any differences are due to underlying differences in expression.  Other methods which apply a scaling factor to each sample, such as Trimmed-mean of M values (TMM) or Quantile normalization, also rely on this assumption.  In the parlance of compositional data these methods assume \emph{Compositional Invariance}, i.e. the underlying composition is statistically independent of the total size of the composition (the total counts for a sample, $t$).\\

Compositional invariance is an important property for RNA-Seq data which enables the comparison of samples with differing read depths.  However, it is well documented that the quality of RNA-Seq depends on the read depth of the sequencing run with higher read-depths associated with higher quality data~\cite{Tarazona2011,Sims2014}. Read depth may affect the measurement of relative abundances for the target RNA sequences as some targets may receive proportionally more reads as the read depth increases.  This would be a direct violation of compositional invariance and could lead seemingly differential expression between samples with different read depths, even after normalization.\\


Testing for compositional invariance in high-dimensional RNA-Seq assays is important to ensure that the differences in expression among samples is independent of the differences in total counts among samples.  Aitchison~\cite{Aitchison1986} outlined a simple model for testing compositional covariance using the ALR transformation.  \\

1. transform using ALR so that we can use mulivariate normal methods
  1b. results to not depend on choice of divisor
2. test hypothesis that $H_0$: $\beta_1 = \ldots = \beta_d = 0$
  2b.  P(reject $H_0$ | Y, t) $\neq$ 0.05 due to multiple testing so need to apply a correction
  2c. Likely to have small sample size so low power to reject null
    i. not enough power to demonstrate equivalence
    ii. Compare effect sizes? i.e. is the DE more related to total than treatment? How to do this with discrete treatment groups?
    iii. Create a model which simulatenously estimates effects and controls for size effects?
    
    
    
  

\begin{equation}
\left[y_1 \ldots y_d \right] = 
\left[
\begin{array}{cc}
1 & t
\end{array}
\right]
\left[
\begin{array}{ccc}
\alpha_1 & \cdots & \alpha_d\\
\beta_1 & \cdots & \beta_d
\end{array}
\right] 
+
\left[e_1 \ldots e_d \right]
\label{matrixModel}
\end{equation}


\section{Batch Effects and Normalization}

Batch effects arising from differing labratory conditions or operator differences have been identified as a problem in high-throughput measurement systems~\cite{leek2010, chen2011}.  Identifying and controlling for batch effects is a critical step in the transition of RNA-Seq from the lab to the clinic.  Batch effects are typically identified with a hierarchical clustering (HC) method or principal components analysis (PCA).  For both methods, the multivariate distance between the samples is visualized. either in a biplot for PCA or a dendrogram for HC, to check for the existence of clusters of samples related to batch. % and removed through various normalization methods~\cite{Robinson2007, Anders2010, Robinson2010, Law2014, leek2014}.  \\ %I wonder if I should move that last line
The compositional nature of RNA-Seq data has important implications for the detection of batch effects due to the incompatibility with standard measures of distance between compositions as noted above~\cite{Aitchison1986,Martin-Fernandez1998}.\\  %The CLR transformation facilitates both batch effect detection and normalization.  The CLR transformed covariance matrix is suitable for exploration through PCA (using biplots)~\cite{Aitchison2002} or hierarchical clustering using standard Euclidean or Mahalanobis distance~\cite{Martin-Fernandez1998}.  \\

The next generation sequencing process results in arbitrary differences in scale among samples as some samples will receive more total reads than others. Principle components analysis is sensitive to differences in scale among the variables, failure to remove these difference can mask potential batch effects and leave unwanted technical variation in the data.  Most normalization methods use a scaling factor calculated for each sample to rescale the read count for each gene within the sample~\cite{Dillies2013}.  The CLR transformation can similarly be viewed as a scaling normalization (with the scale factor chosen as the inverse of the geomtric mean $1/g(x)$).  Unlike other normalization methods, the CLR transformation has the added benefit of being applied at the individual sample level, not experiment wise, and requires no assumptions about differential expression unlike other popular normalizations.  This makes it particularly well suited for the clinic where there are generally no reference samples for normalization.\\

Aitchison demonstrated that the CLR transformation has several other useful properties in addition to rescaling the data~\cite{Aitchison1986}, particularly with respect to PCA biplots~\cite{Aitchison2002}.  Most notably for the detection of batch effects, the distance between any two points representing samples in the form-biplot approximates the Euclidean distance between the two samples.  The CLR transformation retains the property that this distance is at least as great as the distance between any corresponding subset of these two compositions (subspace dominance).  Additionally, the euclidean distance between two CLR transformed samples is location invariant. Other scaling and normalization methods do not necessarily satisfy these properties and, therefore, batch effects may be masked or artificial.\\

%toy example of distance issue when checking for batch effects here

We demonstrate the use of the compositional biplot to detect batch effects using technical replicates of three sample types: brain, plasma, and fresh frozen parafin embedded (FFPE).  Each sample is replicated 8 times in each of 5 sequencing runs for a total of 120 samples.  Samples were prepared using the EdgeSeq Whole Transcriptome miRNA assay which measures 2,280 targets including including 11 control probes and 2,269 unique miRNA probes.  All sequencing was performed on an Illumina Mi-seq$^{(tm)}$ sequencer.\\

We create a second data set, by re-scaling the original data, to better illustrate the effects of changes in read depth on batch effect detection.  To re-scale the samples from the original we multiply every read count in a given sample by a factor, ranging from 0.5 to 1.5, randomly generated from the uniform distribution.  We then obtain a new data set in which the proportions between the read counts remains unchanged but the variance in the total number of reads among the samples is increased.\\ 


We perform a PCA on log-transformed and CLR transformed data.  We then construct form-biplots of the first two principle components for each transformed data set (Fig.~\ref{rawPCA}).  The differences between the 3 samples types (brain, plasma, and FFPE) dominate the first two principle componenets for both data sets.  However, the CLR transformed data provides tighter clusters, relative to the distance between the clusters, than the log-transformed raw data.  There is also a single FFPE sample which is closer to the brain samples than the other samples.  It is worth noting that this sample would have been removed using our proposed quality control metric.\\

\begin{figure}
\includegraphics[scale=0.4]{./Figures/IO_PCA_2plot}
\label{rawPCA}
\caption{Principle component analysis of A) log-transformed and B) CLR-transformed read count data.  The differences between sample types is much greater than the batch effects in both transformation.  The CLR transformation results in tighter sample type clusters resulting from less variation along the first principle component. }
\end{figure}

Since the sample type differences overwhelm the potential batch effects we performed a second PCA on only the brain samples for both transformed data sets (Fig.~\ref{rawPCAbrain}).  Both biplots exhibit clustering by batch but the CLR transformed data shows better separation between the batches, although batches are still overlapping.  \\

\begin{figure}
\includegraphics[scale=0.4]{./Figures/IO_PCA_Brain_logRaw_CLR}
\label{rawPCAbrain}
\caption{Principle component analysis of only brain samples from A) log-transformed and B) CLR-transformed read count data. The batch effects are more easliy identified in the CLR transformed data.}
\end{figure}

Some of the batch effects detected in the log-transformed data may be attributable to the differnces in total reads between batches.  By randomly re-scaling each sample by a constant we are able to break the realtionship between batch and the total reads in a sample. Figure~\ref{rescaledPCA} gives the biplots for log-transformed and CLR-transformed randomly re-scaled data.  The sample type clusters in the log-transformed data become more diffuse while the CLR-transformed biplot remains unchanged.  Most notably, the batch effects previously visible in the log-transformed brain samples become completely obscured in the randomly re-scaled data but remain unchanged in the CLR-transformed data (Fig.~\ref{rescaledPCAbrain}).  

\begin{figure}
\includegraphics[scale=0.4]{./Figures/IO_PCA_Brain_logRaw_CLR_perturbed}
\label{rescaledPCAbrain}
\caption{Principle components analysis of the randomly re-scaled brain samples for A) log-transformed and B) CLR-transformed read count data.  The batch effects visual in the log-tranformed raw data disappear after random re-scaling whereas the batch effects remain identifiable in the CLR transformed data.}
\end{figure}

\FloatBarrier
\section{Discussion}

Our sample quality control metric can identify problematic samples which arise from multiple failure modes, e.g. a low quality sample or a sequencing problem.  However, it is conceivable that a sample might have an unusually low (or high) number of reads and still provide quality information.  In certain experiemental designs one might be able to further evaluate these samples with a PCA biplot on the CLR transformed data. In our PCA analysis we identified a FFPE sample which would have failed our quality control and was clearly very different from the other technical replicates.  However, if this sample had remained quite similar to the other FFPE replicates this would have provided information that the sample may still be valuable.  In this way, the quality control metric and PCA biplot can be used in tandem to provide additional information about the quality of a sample.\\

The principal components analysis biplot is a well know dimension reduction visualization.  For the current data the dimension is reduced from 2,280 probes to 2 principle components.  The utlity of the data reduction, including the quality of the approximation of the multivariate distance between the samples, is proportional to the amount of variance explained by these two principle components. In our data the first two principle components explain between 72 and 21 percent of the variation in the data.  The analysis with the lowest percent of variation explained by the first 2 components is of the CLR-transformed brain samples.  Surprisingly, batch effects are still visible in this plot, in which case they can be removed~\cite{Luo2010}.  \\

As RNA-Seq makes the transition from the research laboratory to the clinic there is a need for robust quality control metrics.  The realization that RNA-Seq data are compositional opens the door to the existing body of theory and methods developed by John Atichison and others.  We show that the properties of compositional data can be leveraged to develop new metrics and enhance existing methods.\\


%ask Shripad about slide 59 from his defense Re: interpretation of the biplot on the raw log-transformed data
\newpage
\printbibliography


<<Set_up, echo = FALSE, message = FALSE, eval = FALSE>>=
library(HTGPackage)
library(car)
library(tidyverse)
library(compositions)
library(reshape2)
library(cowplot)

plotPCA <- function(data, annodata, projname, Max=80, pc1 = "PC1", pc2 = "PC2", scale = FALSE){
  x <- t(data)
  pcares <- prcomp(x, scale = scale)
  print(summary(pcares))
  pvar <- summary(pcares)$importance[3, 2]
  plot(pcares,type="l")
  pcavect<-pcares$x[,1:5]
  indanno<-intersect(row.names(pcavect),row.names(annodata))
  pcavect<-pcavect[indanno,]
  anno.pca<-annodata[indanno,]
  pcadata <- cbind(anno.pca, pcavect)
  return(list(pcadata, pvar))
}


pcaBiplot <- function(data,
                      printSum = FALSE
                      )
{
  
  #############################################################################
  #############################################################################
  ## This function conducts a PCA and prepares data for producing a biplot
  #############################################################################
  #############################################################################
  
  pcadf <- data.matrix(data)
  
  #perform PCA
  pca <- prcomp(t(pcadf), retx = TRUE)
  
  if(printSum) print(summary(pca))
  
  #Get proportion of variance explained by first 2 comps
  pvar <- summary(pca)$importance[3, 2]
  
  #-----Create biplot data for use with ggplot-----#
  nobs.factor <- sqrt(nrow(pca$x) - 1)
  d <- pca$sdev
  u <- sweep(pca$x, 2, 1/(d * nobs.factor), FUN = "*")
  v <- pca$rotation
  #select first two PCs
  df.u <- as.data.frame(sweep(u[, 1:2], 2, c(1,1), FUN = "*"))
  v <- sweep(v, 2, d, FUN = "*")
  df.v <- as.data.frame(v[, 1:2])
  names(df.u) <- c("xvar", "yvar")
  names(df.v) <- names(df.u)
  df.u <- df.u * nobs.factor
  r <- sqrt(qchisq(0.69, df = 2)) * prod(colMeans(df.u^2))^(1/4)
  v.scale <- rowSums(v^2)
  df.v <- r * df.v/sqrt(max(v.scale))
  
  df.v$angle <- with(df.v, (180/pi) * atan(yvar/xvar))
  df.v$hjust = with(df.v, (-.5 * sign(xvar))/2)
  
  return(list(df.v = df.v, df.u = df.u, pvar = pvar))
}


getPlates <- function(x){
  df <- as.data.frame(x)
  df$Proc <- gsub(".*(P\\d{2}).*", "\\1", df$Sample.Name)
  df$Day <- ifelse(grepl("D", df$Sample.Name), gsub(".*(D\\d{1}).*", "\\1", df$Sample.Name), "D1")
  df$Plate <- factor(paste0(df$Proc, "_", df$Day))
  return(df)
}

getTots <- function(x){#use t-list
  df <- as.data.frame(t(x[, -1]))
  names(df) <- make.names(x[, 1])
  df$row <- gsub("(\\w{1})\\d{1,2}$", "\\1", df$Well)
  df$column <- gsub("\\w{1}(\\d{1,2})$", "\\1", df$Well)
  df$Total.Reads <- as.numeric(as.character(df$Total.Counts))
  df <- df[which(!grepl("No_Sample", df$Sample.Name)), ]
  return(df)
}

getTots_mi <- function(x){#use t-list
  df <- as.data.frame(t(x))
  df$row <- gsub("(\\w{1})\\d{1,2}$", "\\1", df$Well)
  df$column <- gsub("\\w{1}(\\d{1,2})$", "\\1", df$Well)
  df$Total.Reads <- as.numeric(as.character(df$Total.Reads))
  df <- df[which(!grepl("No_Sample", df$Sample.Name)), ]
  return(df)
}

MFtrans <- function(x){
  delta <- 0.55/sum(x)
  tdelta <- sum(x == 0) * delta
  cx <-  x/sum(x)
  cxt <- ifelse(cx == 0, delta, cx * (1-tdelta))
  return(cxt)
}

#CLR transformation after Martin-Fernandez zero transformation
MFtrans.clr <- function(x){#apply to a vector
  cxt <- MFtrans(x)
  ccxt <- log(cxt) - sum(log(cxt))/length(cxt)
  return(ccxt)
}


#Make the legend pretty when it is below the graph
fancy_scientific <- function(l) {
     # turn in to character string in scientific notation
     l <- format(l, scientific = TRUE)
     # quote the part before the exponent to keep all the digits
     l <- gsub("^(.*)e\\+", "'\\1'e", l)
     # turn the 'e+' into plotmath format
     l <- gsub("e", "%*%10^", l)
     # return this as an expression
     parse(text=l)
}

load("./Data/IO_repro_data_lists.Rdata")
load("./Data/miRNA_Data_lists.Rdata")
raw.w.mi <- plyr::join_all(dflist_mi, by = "X1")
names(raw.w.mi) <- make.names(raw.w.mi[3, ])
rownames(raw.w.mi) <- make.names(raw.w.mi[, 1])
@


<<IO_Repro_Study, echo = FALSE, message = FALSE, eval = FALSE>>=

#----- Heat Maps -----#


tots <- lapply(tlist, getTots)

tots <- lapply(tots, getPlates)

#Choose P86 and ignore P02
totl <- do.call(rbind, tots)
totl <- totl[which(!grepl("P02", totl$Proc)),]

#define order of the plates for other plots
IO_repro_plates <- levels(totl$Plate)
totl$column <- factor(totl$column, levels = as.character(1:12))


totl$colCompressed <- factor(ifelse(totl$column %in% c(4,7,10), 1, 
                             ifelse(totl$column %in% c(5,8,11), 2, 3)))
totl$PlateGen <- Recode(totl$Plate, "'P86_D1' = 'Run 1'; 'P88_D1' = 'Run 2'; 'P35_D1' = 'Run 3'; 'P86_D2' = 'Run 4'; 'P86_D3' = 'Run 5'")



IOrawTotalsCompressed <- ggplot(totl, aes(x = colCompressed, y = row)) + geom_tile(aes(fill = Total.Reads)) + facet_wrap(~PlateGen, ncol = 5) + plotTheme()  +  xlab("Sample Column") + ylab("Sample Row")  + scale_fill_continuous("Total Reads", labels = fancy_scientific, guide = guide_legend(label.theme = element_text(angle = 45), label.position = "bottom", label.hjust = .5, label.vjust = .5, direction = "horizontal", keywidth = 2))
ggsave("./Figures/IO_Repro_TotalCountHeatMap_RawTotals_Compressed.png", IOrawTotalsCompressed, width = 14 , height = 5)

TotalBoxplot_IO <- ggplot(totl, aes(x = 1, y = Total.Reads)) + geom_boxplot(outlier.color = "red") + facet_wrap(~PlateGen, ncol = 5) + plotTheme(axis.text.x = element_blank(), axis.text.y = element_text(angle = 90, hjust = .5)) + xlab("")



Total_Combined_IO <- plot_grid(TotalBoxplot_IO, IOrawTotalsCompressed, labels = c("A", "B"), nrow = 2, ncol =1)
ggsave("./Figures/IO_Repro_Combined_RawTotals.png", Total_Combined_IO, width = 14 , height = 10)





#CLR the total reads
clrReads <- function(x){
   cbind(x, CLR = as.vector(clr( acomp( as.numeric(as.character(x$Total.Counts)) ), detectionlimit = 0 )))
}
# tots.clr <- lapply(tots, FUN = clrReads)
CLRTotals <- do.call(rbind, tots)
#randomly remove P02 processor
CLRTotals <- CLRTotals[which(!grepl("P02", CLRTotals$Plate)), ]
CLRTotals$Plate <- factor(CLRTotals$Plate)
#split by plate to perform clr
CLRsplit <- split(CLRTotals, CLRTotals$Plate)
#CLR transform each plate
CLRsplit <- lapply(CLRsplit, clrReads)
#re-assemble data
CLRTotals <- do.call(rbind, CLRsplit)
CLRTotals$column <- factor(CLRTotals$column, levels = 1:12)
CLRTotals$Plate <- factor(CLRTotals$Plate, levels = IO_repro_plates)

# IOCLRTots <- ggplot(CLRTotals, aes(x = column, y = row)) + geom_tile(aes(fill = CLR)) + facet_wrap(~Plate, ncol = 5) + plotTheme(legend.position = "right") +  xlab("Plate Column") + ylab("Plate Row")
# ggsave("./Figures/IO_Repro_TotalCountHeatMap_CLRTotals.png", IOCLRTots, width = 14 , height = 5)

CLRTotals$colCompressed <- factor(ifelse(CLRTotals$column %in% c(4,7,10), 1, 
                             ifelse(CLRTotals$column %in% c(5,8,11), 2, 3)))
CLRTotals$PlateGen <- Recode(CLRTotals$Plate, "'P86_D1' = 'Run 1'; 'P88_D1' = 'Run 2'; 'P35_D1' = 'Run 3'; 'P86_D2' = 'Run 4'; 'P86_D3' = 'Run 5'")

IOCLRTotsCompressed <- ggplot(CLRTotals, aes(x = colCompressed, y = row)) + geom_tile(aes(fill = CLR)) + facet_wrap(~PlateGen, ncol = 5) + plotTheme() +  xlab("Sample Column") + ylab("Sample Row") + scale_fill_continuous("CLR Transformed\nTotal Reads")
ggsave("../Paper1/Figures/IO_Repro_TotalCountHeatMap_CLRTotals_Compressed.png", IOCLRTotsCompressed, width = 14 , height = 5)

CLRBoxplot_IO <- ggplot(CLRTotals, aes(x = 1, y = CLR)) + geom_boxplot(outlier.color = "red") + facet_wrap(~PlateGen, ncol = 5) + plotTheme(axis.text.x = element_blank(), axis.text.y = element_text(angle = 90, hjust = .5))

CLR_Combined_IO <- plot_grid(CLRBoxplot_IO, IOCLRTotsCompressed, labels = c("A", "B"), nrow = 2, ncol =1)
ggsave("../Paper1/Figures/IO_Repro_Combined_CLR.png", CLR_Combined_IO, width = 14 , height = 10)

@



<<PCA_miRNA, echo = FALSE, results = 'hide', warning = FALSE, fig.keep = 'none', eval = FALSE>>=
annodf.mi <- data.frame(SampleID = names(raw.w.mi)[-1])
annodf.mi$Run <- gsub("^(run\\d{3})\\..*", "\\1", annodf.mi$SampleID)
annodf.mi$Run <- paste("Run", as.numeric(as.factor(annodf.mi$Run)))
annodf.mi$SampType <- gsub("(^run\\d{3})\\.(\\w+)\\_\\d\\_\\d$", "\\2", annodf.mi$SampleID)
rownames(annodf.mi) <- annodf.mi$SampleID

pcaDat.mi.orig <- data.matrix(raw.w.mi[-c(1:5), -c(1, 36)])

#create matrix of multipliers to change scaling of raw data
set.seed(390)
sc <- runif(ncol(pcaDat.mi.orig), .5, 1.5)
scmat <- matrix(nrow = nrow(pcaDat.mi.orig), ncol = ncol(pcaDat.mi.orig))
for(i in 1:ncol(scmat)){
  scmat[, i] <- sc[i]
}

#Shift the location of every sample by the same amount
prt <- runif(nrow(pcaDat.mi.orig))
prt <- prt/sum(prt)



pcaDat.mi.p <- pcaDat.mi.orig
#Randomly scale raw data
# pcaDat.mi <- scmat * pcaDat.mi


#perturb raw data the same amount for every sample
for( i in 1:ncol(pcaDat.mi.p)){
  #first close each sample
  pcaDat.mi.p[, i] <- pcaDat.mi.p[, i]/sum(pcaDat.mi.p[, i])
  #apply the perturbation
  pcaDat.mi.p[, i] <- (pcaDat.mi.p[, i] * prt)
  #Reclose the data
  pcaDat.mi.p[, i] <- pcaDat.mi.p[, i]/sum(pcaDat.mi.p[, i])
}

###############################################################################
###############################################################################
#First perform PCA on log-transformed data
###############################################################################
###############################################################################

#log transform
logdat <- apply(pcaDat.mi.orig[-c(1:11), ], c(1,2), function(x) log2(x + 1))

#perform PCA
pcalogdat <- pcaBiplot(logdat)

pcalogdat$df.u$SampleID <- rownames(pcalogdat$df.u)
pcalogdat$df.u <- merge(pcalogdat$df.u, annodf.mi, by = "SampleID")

#biplot of the PCA for log-raw data
logdatPCA <- ggplot(pcalogdat$df.u, aes(x = xvar, y = yvar, color = Run, shape = SampType)) +
  geom_point( size = 3)  +
  coord_equal() + 
  xlab("PC1") +
  ylab("PC2") +
  ggtitle(paste0("Cum. proportion of var. = ", round(pcalogdat$pvar, 2))) +
  scale_shape_discrete("Sample Type")
ggsave("./Figures/miRNA_Repro_PCA_log(raw).png", ggpcal.mi.l, width = 9, height = 8 )

#Only Brain
logdat.brain <- logdat[, which(grepl("Brain", colnames(logdat)))]

pcalogdat.brain <- pcaBiplot(logdat.brain)
pcalogdat.brain$df.u$SampleID <- rownames(pcalogdat.brain$df.u)
pcalogdat.brain$df.u <- merge(pcalogdat.brain$df.u, annodf.mi, by = "SampleID")

logdatPCA.brain <- ggplot(pcalogdat.brain$df.u, aes(x = xvar, y = yvar, color = Run)) + 
    geom_point( size = 3) +
      ylab("PC2") +
      xlab("PC1") +
    coord_equal() + #ylim(c(-30, 100)) + xlim(c(-50, 160)) +
  ggtitle(paste0("Cum. proportion of var. = ", round(pcalogdat.brain$pvar, 2)))
ggsave("./Figures/miRNA_Repro_PCA_log(raw)_BrainOnly_perturbed.png", ggpcal.mi.l.brain, width = 9, height = 8 )


###############################################################################
#Perform PCA on the perturbed data after log transformation
###############################################################################

logdat.p <- apply(pcaDat.mi.p[-c(1:11), ], c(1,2), function(x) log2(x*10e6 + 1))


pcalogdat.p <- pcaBiplot(logdat.p)

pcalogdat.p$df.u$SampleID <- rownames(pcalogdat.p$df.u)
pcalogdat.p$df.u <- merge(pcalogdat.p$df.u, annodf.mi, by = "SampleID")

#biplot of the PCA for log-raw data
logdatPCA.p <- ggplot(pcalogdat.p$df.u, aes(x = xvar, y = yvar, color = Run, shape = SampType)) +
  geom_point( size = 3)  +
  coord_equal() + 
  xlab("PC1") +
  ylab("PC2") +
  ggtitle(paste0("Cum. proportion of var. = ", round(pcalogdat.p$pvar, 2))) +
  scale_shape_discrete("Sample Type")
ggsave("./Figures/miRNA_Repro_PCA_log(raw).png", ggpcal.mi.l, width = 9, height = 8 )


logdat.p.brain <- logdat.p[, which(grepl("Brain", colnames(logdat.p)))]
pcalogdat.p.brain <- pcaBiplot(logdat.p.brain)
pcalogdat.p.brain$df.u$SampleID <- rownames(pcalogdat.p.brain$df.u)
pcalogdat.p.brain$df.u <- merge(pcalogdat.p.brain$df.u, annodf.mi, by = "SampleID")

logdatPCA.brain.p <- ggplot(pcalogdat.p.brain$df.u, aes(x = xvar, y = yvar, color = Run)) + 
  geom_point( size = 3) +
  ylab("PC2") +
  xlab("PC1" ) +
  coord_equal() + #ylim(c(-30, 100)) + xlim(c(-50, 160)) +
  ggtitle(paste0("Cum. proportion of var. = ", round(pcalogdat.p.brain$pvar, 2)))
ggsave("./Figures/miRNA_Repro_PCA_log(raw)_BrainOnly_perturbed.png", ggpcal.mi.l.brain, width = 9, height = 8 )


###############################################################################
# Perform PCA on CLR data
###############################################################################


clrdat <- pcaDat.mi.orig[-c(1:11), -35]

clrdat <- as.data.frame(apply(clrdat, 2, MFtrans.clr))

pcaclrdat <- pcaBiplot(clrdat)
pcaclrdat$df.u$SampleID <- rownames(pcaclrdat$df.u)
pcaclrdat$df.u <- merge(pcaclrdat$df.u, annodf.mi, by = "SampleID")

clrdatPCA <- ggplot(pcaclrdat$df.u, aes(x= xvar, y= yvar, color=Run)) +
  geom_point( size = 3)   +
  coord_equal()  +
  xlab("PC1") +
  ylab("PC2") +
  ggtitle(paste0("Cum. proportion of var. = ", round(pcaclrdat$pvar, 2)))

ggsave("./Figures/miRNA_Repro_PCA_CLR_BrainOnly.png", ggpcac.brain, width = 9, height = 8 )



clrdat.brain <- pcaDat.mi.orig[-c(1:11), which(grepl("Brain", colnames(pcaDat.mi.orig)))]

clrdat.brain <- as.data.frame(apply(clrdat.brain, 2, MFtrans.clr))

pcaclrdat.brain <- pcaBiplot(clrdat.brain)
pcaclrdat.brain$df.u$SampleID <- rownames(pcaclrdat.brain$df.u)
pcaclrdat.brain$df.u <- merge(pcaclrdat.brain$df.u, annodf.mi, by = "SampleID")

clrdatPCA.brain <- ggplot(pcaclrdat.brain$df.u, aes(x= xvar, y= yvar, color=Run)) +
  geom_point( size = 3)   +
  coord_equal()  +
  xlab("PC1") +
  ylab("PC2") +
  ggtitle(paste0("Cum. proportion of var. = ", round(pcaclrdat.brain$pvar, 2)))

ggsave("./Figures/miRNA_Repro_PCA_CLR_BrainOnly.png", ggpcac.brain, width = 9, height = 8 )

###############################################################################
#CLR of perturbed data
###############################################################################

clrdat.p <- pcaDat.mi.p[-c(1:11), -35]*10e6

clrdat.p <- as.data.frame(apply(clrdat.p, 2, MFtrans.clr))

pcaclrdat.p <- pcaBiplot(clrdat.p)
pcaclrdat.p$df.u$SampleID <- rownames(pcaclrdat.p$df.u)
pcaclrdat.p$df.u <- merge(pcaclrdat.p$df.u, annodf.mi, by = "SampleID")

clrdatPCA.p <- ggplot(pcaclrdat.p$df.u, aes(x= xvar, y= yvar, color=Run)) +
  geom_point( size = 3)   +
  coord_equal()  +
  xlab("PC1") +
  ylab("PC2") +
  ggtitle(paste0("Cum. proportion of var. = ", round(pcaclrdat.p$pvar, 2)))

ggsave("./Figures/miRNA_Repro_PCA_CLR_BrainOnly.png", ggpcac.brain, width = 9, height = 8 )


clrdat.p.brain <- as.data.frame(apply(pcaDat.mi.p[-c(1:11), ], 2, MFtrans.clr))

pcaclrdat.p.brain <- pcaBiplot(clrdat.p.brain)
pcaclrdat.brain$df.u$SampleID <- rownames(pcaclrdat.brain$df.u)
pcaclrdat.brain$df.u <- merge(pcaclrdat.brain$df.u, annodf.mi, by = "SampleID")

clrdatPCA.brain <- ggplot(pcaclrdat.brain$df.u, aes(x= xvar, y= yvar, color=Run)) +
  geom_point( size = 3)   +
  coord_equal()  +
  xlab("PC1") +
  ylab("PC2") +
  ggtitle(paste0("Cum. proportion of var. = ", round(pcaclrdat.brain$pvar, 2)))
ggsave("./Figures/miRNA_Repro_PCA_CLR.png", ggpcac, width = 9, height = 8 )



pcaDatc.mi.brain.p <- pcaDatc.mi.p[, which(grepl("Brain", colnames(pcaDatc.mi.p)))]
pcplotdatc.mi.brain.p <- plotPCA(pcaDatc.mi.brain.p, annodf.mi, scale = FALSE)
ggpcac.brain <- ggplot(pcplotdatc.mi.brain.p[[1]], aes(x= PC1, y= PC2, color=Run, label = SampleID)) +
    geom_point( size = 3)   +
    coord_equal() +
    ggtitle(paste0("Cum. proportion of var. = ", round(pcplotdatc.mi.brain[[2]], 2)))
ggsave("./Figures/miRNA_Repro_PCA_CLR_BrainOnly.png", ggpcac.brain, width = 9, height = 8 )


pcaPlots2 <- plot_grid(ggpcal.mi.l, ggpcac, ncol = 2, nrow = 1, labels = c("A", "B"))
ggsave("../Paper1/Figures/miRNA_PCA_2plot.png", pcaPlots2, height = 8, width = 16)

brainPCA <- plot_grid(ggpcal.mi.l.brain, ggpcac.brain, ncol = 2, nrow = 1, labels = c("A", "B"))
ggsave("../Paper1/Figures/miRNA_PCA_Brain_logRaw_CLR_perturbed.png", brainPCA, height = 8, width = 16)


brainPCAperturbed <- plot_grid(ggpcal.mi.l.brain.perturbed, ggpcac.brain, ncol = 2, nrow = 1, labels = c("A", "B"))
ggsave("../Paper1/Figures/miRNA_PCA_Brain_logRaw_CLR_perturbed.png", brainPCAperturbed, height = 8, width = 16)



#use gPCA method to test for remaining batch effects for each method.
# library(gPCA)
# lrawBE <- gPCA.batchdetect(x = t(pcaDatl.mi), as.numeric(factor(annodf.mi$Plate)), center = FALSE, seed = 1014)
# lrawGpca <- as.data.frame(lrawBE$PCg)
# lrawGpca$Plate <- gsub("(^run\\d{3})\\.(\\w+)\\_.+", "\\1", rownames(lrawGpca))
# lrawGpca$SampType <- gsub("(^run\\d{3})\\.(\\w+)\\_\\d\\_\\d", "\\2", rownames(lrawGpca))
# ggplot(lrawGpca, aes(x = V1, y = V2)) + geom_point(aes(color = Plate, shape = SampType), size= 3) + xlab("gPC1") + ylab("gPC2") + ggtitle("Guided PCA on log(Raw) Data") #+ coord_equal()
# 
# cpmBE <- gPCA.batchdetect(x = t(pcaDat.mi), as.numeric(factor(annodf.mi$Plate)), center = FALSE, seed = 1014)
# cpmGpca <- as.data.frame(cpmBE$PCg)
# cpmGpca$Plate <- gsub("(^run\\d{3})\\.(\\w+)\\_.+", "\\1", rownames(cpmGpca))
# cpmGpca$SampType <- gsub("(^run\\d{3})\\.(\\w+)\\_\\d\\_\\d", "\\2", rownames(cpmGpca))
# ggplot(cpmGpca, aes(x = V1, y = V2)) + geom_point(aes(color = Plate, shape = SampType), size= 3) + xlab("gPC1") + ylab("gPC2") + ggtitle("Guided PCA on log(CPM) Data") #+ coord_equal()
# 
# qnormBE <- gPCA.batchdetect(x = t(pcaDatn.mi), as.numeric(factor(annodf.mi$Plate)), center = FALSE, seed = 1014)
# qnormGpca <- as.data.frame(qnormBE$PCg)
# qnormGpca$Plate <- gsub("(^run\\d{3})\\.(\\w+)\\_.+", "\\1", rownames(qnormGpca))
# qnormGpca$SampType <- gsub("(^run\\d{3})\\.(\\w+)\\_\\d\\_\\d", "\\2", rownames(qnormGpca))
# ggplot(qnormGpca, aes(x = V1, y = V2)) + geom_point(aes(color = Plate, shape = SampType), size= 3) + xlab("gPC1") + ylab("gPC2") + ggtitle("Guided PCA on Quantile Normalized Data") #+ coord_equal()
# 
# mnormBE <- gPCA.batchdetect(x = t(pcaDatm.mi), as.numeric(factor(annodf.mi$Plate)), center = FALSE, seed = 1014, filt = 1000)
# mnormGpca <- as.data.frame(mnormBE$PCg)
# mnormGpca$Plate <- gsub("(^run\\d{3})\\.(\\w+)\\_.+", "\\1", rownames(mnormGpca))
# mnormGpca$SampType <- gsub("(^run\\d{3})\\.(\\w+)\\_\\d\\_\\d", "\\2", rownames(mnormGpca))
# ggplot(mnormGpca, aes(x = V1, y = V2)) + geom_point(aes(color = Plate, shape = SampType), size= 3) + xlab("gPC1") + ylab("gPC2") + ggtitle("Guided PCA on Median Normalized Data") #+ coord_equal()
# 
# clrBE <- gPCA.batchdetect(x = t(pcaDatc.mi), as.numeric(factor(annodf.mi$Plate)), center = FALSE, seed = 1014)
# clrGpca <- as.data.frame(clrBE$PCg)
# clrGpca$Plate <- gsub("(^run\\d{3})\\.(\\w+)\\_.+", "\\1", rownames(clrGpca))
# clrGpca$SampType <- gsub("(^run\\d{3})\\.(\\w+)\\_\\d\\_\\d", "\\2", rownames(clrGpca))
# ggplot(clrGpca, aes(x = V1, y = V2)) + geom_point(aes(color = Plate, shape = SampType), size= 3) + xlab("gPC1") + ylab("gPC2") + ggtitle("Guided PCA on Median Normalized Data") #+ coord_equal()

#can't really find a batch effect in the miRNA data!
@

\end{document}