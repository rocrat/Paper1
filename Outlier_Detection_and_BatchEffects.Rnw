\documentclass{article}
\usepackage{xcolor}
\usepackage[colorlinks=true, linkcolor=blue, citecolor=blue]{hyperref}
\usepackage[backend=bibtex,backref=true,hyperref=true]{biblatex}
\addbibresource{proportionality.bib}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{bbm}
\usepackage{fullpage}
\usepackage{setspace}
\usepackage{placeins}
\usepackage{color}

\usepackage{amsthm}
 
\theoremstyle{definition}
\newtheorem{definition}{Definition}

\definecolor{light-gray}{gray}{0.7}

\doublespacing

\title{Quality control metrics for extraction-free targeted RNA-Seq: methods afforded by a compositional framework.}
\author{Dominic LaRoche \and Dean Billheimer \and Shripad Sinari \and Kurt Michels \and  Bonnie LaFleur}
\begin{document}

\maketitle

\doublespacing
% \section{Abstract}


\section{Introduction}

%-- Introduce the problem and motivate the research -->

We develop quality control diagnostics for targeted RNA-Seq using the theory of compositional data.  Targeted sequencing allows researchers to efficiently measure transcripts of interest for a particular disease by focusing sequencing efforts on a select subset of transcript targets.  Targeted sequencing offers several benefits over traditional whole-transcriptome RNA-Seq for clinical use including the elimination of amplification bias, reduced sequencing cost, and a simplified bioinformatics workflow.  Moreover, extraction-free targeted sequencing technologies, such as HTG EdgeSeq, permit the use of very small sample volumes. However, extraction free technologies create the need for post-sequencing quality control metrics since poor quality samples, which would likely be removed after unsuccessful RNA extraction in extraction-based technologies, can still be sequenced.  The post-sequencing methods described here should be easily extensible to traditional extraction-based RNA-Seq because targeted and traditional RNA-Seq data share many of the same properties.\\


%-- Brief intro to compositional data
Relative frequency measures are characterized as a vector of proportions of some whole.  These proportions are necessarily positive and sum to a constant which is determined by the measurement system and not the measurand.  
Targeted and whole transcriptome RNA-Seq measurements from NGS-based instruments provide only relative frequencies of the measured transcripts.  The measurement technology, along with sample preparation, preclude the measurement of absolute abundance. The total number of reads in a sequencing run for high-throughput RNA-Seq instruments is determined by the maximum number of available reads  and not the absolute number of reads in a sample.  For example, the Illumina Mi-Seq is limited to 25 million reads in a sequencing run while the Roche 454 GS Junior \textsuperscript{(TM)}, with longer read lengths, claims approximately 100,000 reads per run for shotgun sequencing.  These reads are distributed across all of the samples included in a sequencing run and, therefore, impose a total sum constraint on the data.  This constraint cascades down to each probe or tag within a sample which is, in turn, constrained by the total number of reads allocated to the sample thereby creating a natural hierarchical structure to RNA-Seq data.\\

Previous authors have identified the relative abundance nature of RNA-Seq data~\cite{Robinson2007, Anders2010, Robinson2010, Law2014, Lovell2015}.  For example, Robinson and Smyth (2007)~\cite{Robinson2007} consider counts of RNA tags as relative abundances in their development of a model for estimating differential gene expression implemented in the Bioconductor package edgeR.  Similarly, Robinson and Oshlack (2010) explicitly acknowledge the mapped-read constraint when developing their widely used Trimmed-Mean of M-values (TMM) normalization method for RNA-Seq data. Finally, the commonly used log$_2$ Counts per Million (CPM) re-scaling transformation proposed by Law et al. (2014)~\cite{Law2014} divides each sequence count by the total number of reads allocated to the sample thereby transforming the data for each sample into a vector of proportions. \\%However, none of these authors reference the large body of literature on the analysis of compositions.


The positivity and summation constraint complicate the analysis of relative frequency data.  As early as 1896 Karl Pearson~\cite{Pearson1896} identified the spurious correlation problem associated with compositions.  John Aitchison observed that relative frequency data is compositional and developed a methodology based on the geometric constraints of compositions~\cite{Aitchison1986}.  Recent authors have argued that ignoring the sum constraint can lead to unexpected results and erroneous inference~\cite{Lovell2011}.  Despite the evidence that RNA-Seq data are compositional in nature, few researchers have extended the broad set of compositional data analysis theory and operations for use in RNA-Seq analysis problems.  

We provide a brief background on compositional methods.  We then extend existing compositional data methodology to develop two quality control metrics and improve batch effect detection for RNA-Seq data.\\% Finally, we show how compositional properties can be exploited to facilitate exploration of high-dimensional RNA-Seq data.\\

%

\section{Methods}

\subsection{Compositional Data}
%-- CODA intro -->
Compositional data is defined as any data in which all elements are non-negative and sum to a fixed constant~\cite{Aitchison1986}. %-- Establish notation  and data hierarchy-->
For RNA-seq data, the total sum constraint is imposed by the limited number of available reads in each sequencing run.  Since this total differs between sequencing platforms we will refer to the total number of available reads as $\mathbb{T}$. These reads are distributed among the $D$ samples in a sequencing run such that:

\begin{equation}
\sum_{i=1}^{D} t_i = \mathbb{T}
\label{sumt}
\end{equation}

where $t_i$ represents the total reads for sample $i$.  Because of the total sum constraint, the vector $\mathbf{t}$ is completely determined by $D-1$ elements since the $D^{th}$ element of $\mathbf{t}$ can be determined from the other $d = D-1$ elements and the total $\mathbb{T}$:  

\begin{equation}
t_D = \mathbb{T} - \sum_{i=1}^{d} \mathbf{t_i}
\label{sumConst}
\end{equation}

In \ref{sumConst}, any of the elements can be chosen for $t_D$ with the remaining elements labeled $1, ..., d$ in any order~\cite{Aitchison1986}.  Similarly, the total reads for each sample ($t_i$) are distributed among the $P$ transcript targets in the assay such that $\sum_{j=1}^{P} p_{ij} = t_i$, where $p_{ij}$ is the number of reads allocated to target $j$ in sample $i$.  We highlight the hierarchical structure of RNA-Seq data as it leads to useful properties when developing quality control metrics.\\


From equations~\ref{sumt} and~\ref{sumConst} it is clear that the total reads allocated to each of the $D$ samples represent a $D - 1 = d$ dimensional simplex ($\mathcal{S}^d$). This leads to problems when using methods developed for standard Euclidean sample spaces such as interpreting the traditional $D \times D$ covariance structure or measuring the distance between vectors.  In particular, it is clear that for a D-part composition $\mathbf{x}$, $\text{cov}(x_1, x_1+ \cdots +x_D) = 0$  since $x_1 + \cdots + x_D$ is a constant.  Moreover, the sum constraint induces negativity in the covariance matrix,

\begin{equation}
\text{cov}(x_1, x_2) + \cdots + \text{cov}(x_1, x_D) = -\text{var}(x_1).
\label{negbias}
\end{equation}

Equation~\ref{negbias} shows that at least one element of each row of the covariance matrix must be negative. Aitchison refers to this as the ``negative bias difficulty" (although `bias' is not used in the traditional sense;~\cite{Aitchison1986}, p. 53). The structurally induced negative values create problems for the interpretation of the covariance matrix.  Similarly, the use of naive distance metrics in the simplex may not be interpretable as in Euclidean space. Because of these difficulties, standard statistical methodology is not always appropriate~\cite{Aitchison1986} and can produce misleading results~\cite{Lovell2015}.\\


To overcome these obstacles, Aitchison~\cite{Aitchison1980} proposed working in ratios of components. We focus on the Centered Log-Ratio (CLR) which treats the parts of the composition symmetrically and provides an informative covariance structure.  The CLR transformation is defined for a $D$-part composition $\mathbf{x}$ as:
\begin{equation}
y_i  = \text{CLR}(x_i) = log \left(\frac{x_i}{g(\mathbf{x})} \right),
\label{clr}
\end{equation}

where $g(\mathbf{x})$ is the geometric mean of $\mathbf{x}$.  The $D \times D$ covariance matrix is then defined as:

\begin{equation}
\Gamma = \left[\text{cov}\left(y_i, y_j \right): i,\ j = 1, ..., D \right]
\label{gamma}
\end{equation}
\\

The CLR transformation is similar to the familiar Counts per Million (CPM) transformation~\cite{Law2014} defined as, $log_2 \left(\frac{r_{gi}+0.5}{t_i+1} \times 10^6 \right)$, where $r_{gi}$ is the number of sequence reads for each probe ($g$) and sample ($i$), (scaled to avoid zero counts), adjusted for the number of mapped reads (library count) for each sample $t_i$ (scaled by a constant 1 to ensure the proportional read to library size ratio is greater than zero). The primary difference between the CLR and log(CPM) transformations is in the use of the geometric mean in the denominator of the CLR transformation. The use of the geometric mean results in subtracting the mean of the log transformed values from each log-transformed element thereby centering the vector of log-ratio transformed read counts. The difference appears minor but has important implications for the application of several common statistical methods.\\


%%%Need to add in ALR transformation for compositional invariance section
Although the CLR transformation preserves the original dimension of the data, and gives equal treatment to every element of $\mathbf{x}$, the resulting covariance matrix, $\Gamma$, is singular.  Therefore, care should be taken when using general multivariate methods on CLR transformed data. Aitchison~\cite{Aitchison1986} proposed an alternative transformation, the additive log-ratio (ALR), which does not treat the components symmetrically but results in a non-singular covariance matrix.  The ALR transformation is defined as,

\begin{equation}
y_i  = \text{ALR}(x_i) = log \left(\frac{x_i}{x_D} \right),
\label{alr}
\end{equation}

where $x_D$, the D$^{th}$ component of $x$, can be any component.  \\  

As noted above, the compositional geometry must be accounted for when measuring the distance between two compositional vectors or finding the center of a group of compositions~\cite{Aitchison2000}.  Aitchison~\cite{Aitchison1992} outlined several properties for any compositional difference metric which must be met: scale invariance, permutation invariance, perturbation invariance (similar to translation invariance for Euclidean distance), and subcompositional dominance (similar to subspace dominance of Euclidean distance).  The scale invariance requirement is ignorable if the difference metric is applied to data on the same scale (which is generally not satisfied in raw RNA-seq data due to differences in read depth). The permutation invariance is generally satisfied by existing methods such as Euclidean distance~\cite{Martin-Fernandez1998}. However, the perturbation invariance and subcompositional dominance are not generally satisfied~\cite{Martin-Fernandez1998}. \\

Aitchison~\cite{Aitchison1986, Aitchison1992} suggests using the sum of squares of all log-ratio differences.  Billheimer, Guttorp, and Fagan~\cite{Billheimer2001} use the geometry of compositions to define a norm which, along with the perturbation operator defined by Aitchison~\cite{Aitchison1986}, allow the interpretation of differences in compositions. Martin-Fernandez et al.~\cite{Martin-Fernandez1998} showed that applying either Euclidean distance or Mahalanobis distance metric to CLR transformed data satisfies all the requirements of a compositional distance metric. Euclidean distance on CLR transformed compositions is referred to as Aitchison distance:

\begin{equation}
d_A(x_i, x_j) = \left[\sum_{k=1}^D \left( log \left(\frac{x_{ik}}{g(x_i)} \right) - log \left(\frac{x_{jk}}{g(x_j)} \right) \right)^2  \right]^\frac{1}{2}
\label{aitchdist1}
\end{equation}


or

\begin{equation}
d_A(x_i, x_j) = \left[\sum_{k=1}^D \left( clr(x_{ik}) - clr(x_{jk}) \right)^2  \right]^\frac{1}{2}.
\label{aitchdist2}
\end{equation}
\\


To avoid numerical difficulties arising from sequence targets with 0 reads, Martin-Fernandez et al. (2000)~\cite{Martin-Fernandez2000} suggest an additive-multiplicative hybrid transformation.  If zeros are present in the data We recommend using the Martin-Fernandez transformation with a threshold value of $\delta = \frac{0.55}{\text{Total Reads}}$ to account for differences in sequencing depth.  The CLR transformation is then applied to the Martin-Fernandez transformed data which contains no zeros. \\




Up to this point we have referred to the total reads available per sequencing run, $\mathbb{T}$.  However, it is more typical to work with the aligned reads in practice.  The total aligned reads, $T$, is always a fraction of the total reads available for a sequencing run, $\mathbb{T}$.  The fraction of the total reads aligned can be affected by multiple factors, including the choice of alignment algorithm, which we do not address here.  We assume that $T$ imposes the same constraints on the data as outlined above for $\mathbb{T}$ and will refer exclusively to $T$ hereafter.\\  


\section{Fractional Allocation of Aligned Reads to Samples}

Problems with sample quality, library preparation, or sequencing may result in a low number of reads allocated to a given sample within a sequencing run.  The Percent Pass Filter (\% PF) metric provided on Illumina sequencers provides a measure that can identify problems with sequencing that result in a low number of reads allocated to a sample.  However, \% PF will not necessarily catch problems associated with poor sample quality or problems with sample pre-processing since these processes may affect cluster generation, and not just cluster quality.  This is particularly important for extraction-free RNA-Seq technologies, such as the HTG EdgeSeq$^{(tm)}$, which allow for the use of smaller input amounts but lack the intermediate steps for checking sample quality.  There is currently no objective way to evaluate sample quality based on the total number of reads attributed to a sample. We propose a method for objectively identifying problematic samples based on the total number of reads allocated to the sample. \\

For most experimental designs we expect the number of reads allocated to each sample in a sequencing run to arise from the same general data generating mechanism, namely the chemistry of the NGS-based measurement system, regardless of experimental condition.  The objective is then to determine which samples arise from a different mechanism.  Outlier detection is well suited for discovering observations that deviate so much from other observations that they are likely to have arisen from a different mechanism~\cite{Hawkins1980}.  We base our method off Tukey's box-plots~\cite{Tukey1977}, which is a commonly used and robust method for detecting outliers~\cite{Ben-Gal2009}.\\

We expect the total number of reads allocated to each sample, $t_i$, to be equivalent notwithstanding random variation. For a given sequencing run with $D$ samples we define the vector of total reads allocated to each sample as $\mathbf{t}$.  Since the $D$ dimensional vector $\mathbf{t}$ is a composition we have $\mathbf{t} \in \mathcal{S}^{D-1}$, the $D-1$-dimensional simplex. As noted above, traditional statistical methods may not be appropriate for data in the simplex.  Therefore, we map $\mathbf{t} \in \mathcal{S}^{D-1} \rightarrow \mathbf{x} = CLR(\mathbf{t}) \in \mathcal{R}^D$ using the Centered Log Ratio transformation~\ref{clr}.  We then apply Tukey's method for detecting outliers to $\mathbf{x}$, which simply identifies those observations which lie outside 1.5 times the inter-quartile range.

\theoremstyle{definition}
\begin{definition}
$x_i$ is a quality control sample failure if $x_i <$ lower-quartile$- 1.5 \times$ IQR \emph{or}  $x_i >$ upper-quartile$+ 1.5 \times$ IQR, where IQR is the interquartile range of $\mathbf{x}$.
\end{definition}

We demonstrate the utility of our sample quality control measure using two sets of targeted RNA-Seq data: 1) 120 mRNA technical replicate universal-RNA samples prepared with the HTG EdgeSeq Immuno-Oncology assay and sequenced in 5 different equally sized runs, and 2) 105 miRNA technical replicate samples of human plasma, FFPE tissue, and Brain RNA prepared with the HTG EdgeSeq Whole Transcriptome miRNA assay.  These two data sets differ in the both the type of RNA (mRNA versus miRNA) and the number of sequence targets in each assay (558 versus 2,280 targets, for the mRNA and miRNA assays respectively).  All samples were prepared for sequencing using the HTG EdgeSeq Processor and sequenced with an Illumina Mi-Seq sequencer.\\

We compare the utility of our method to evaluation of the un-transformed total counts.  Figure~\ref{totalFig} shows a boxplot and heat-map of the total number of reads allocated to each sample for each of 5 sequencing runs.  Figure~\ref{clrFig} shows the same data after CLR transformation.  After transformation the poor samples become much more visually evident in the heat maps.  Additionally, the ability to detect outlying values increases and the number of poor samples detected increases from 1 to 6.  \\

\begin{figure}
\includegraphics[scale=.5]{./Figures/IO_Repro_Combined_RawTotals}
\caption{A) Distributions of total reads allocated to each sample in 5 runs on an Illumina Mi-Seq sequencer. Only 1 sample is identified as a problematic sample. B) Heat-maps showing the relative totals for each sample within each run.  The darker heat-maps for runs 4 and 5 reflect the generally lower number of total reads in those sequencing runs as compared to runs 1 and 2.  This is caused by normal variation in the number of reads available in a sequencing run.}
\label{totalFig}
\end{figure}
 
\begin{figure}
\includegraphics[scale=.5]{./Figures/IO_Repro_Combined_CLR}
\caption{A) Distributions of CLR transformed total reads allocated to each sample in 5 runs on an Illumina Mi-Seq sequencer. After CLR transformation, 6 samples are identified as a problematic. B) Heat-maps showing the relative CLR transformed totals for each sample within each run.}
\label{clrFig}
\end{figure}

\FloatBarrier
\section{Testing for Compositional Invariance}

%Traditional testing for CI has several problems
%   - Choice of denominator will impact the number of probes which exhibit CI violations
%   - Increases in variance associated with low reads will make it hard to identify CI violations
%   - How much CI violation is too much?  100 betas != 0?  200? 1000?



Normalization and standardization methods for RNA-Seq generally assume that the total number of reads assigned to a sample does not affect the observed relative frequencies of probes within an assay.  For example, implicit in the CPM transformation is the idea that if you re-scale the counts (by dividing by the total for each sample) then the resulting counts are comparable and any differences are due to underlying differences in expression.  Other methods which apply a scaling factor to each sample, such as Trimmed-mean of M values (TMM) or Quantile normalization, also rely on this assumption.  In the parlance of compositional data these methods assume \emph{Compositional Invariance}, i.e. the underlying composition is statistically independent of the total size of the composition (the total counts for a sample, $t$).\\

Compositional invariance (CI) is an important property for RNA-Seq data which enables the comparison of samples with differing read depths.  However, it is well documented that the quality of RNA-Seq depends on the read depth of the sequencing run with higher read-depths associated with higher quality data~\cite{Tarazona2011,Sims2014}. Read depth may affect the measurement of relative abundances for the target RNA sequences as some targets may receive proportionally more reads as the read depth increases.  This would be a direct violation of CI and could lead seemingly differential expression between samples with different read depths, even after normalization.  Another form of CI violation, that is perhaps more likely in RNA-Seq experiments, is the dependence between the variance of read counts and the read depth.\\


Aitchison~\cite{Aitchison1986} outlined a simple model for testing compositional covariance using the ALR transformation,  \\

\begin{equation}
\left[y_1 \ldots y_d \right] = 
\left[
\begin{array}{cc}
1 & t
\end{array}
\right]
\left[
\begin{array}{ccc}
\alpha_1 & \cdots & \alpha_d\\
\beta_1 & \cdots & \beta_d
\end{array}
\right] 
+
\left[e_1 \ldots e_d \right],
\label{matrixModel}
\end{equation}

where $y_1 \ldots y_d$ are the $d$ ALR transformed components, $t$ is the vector of sample total aligned reads, $\alpha_1 \ldots \alpha_d$ are the probe specific log-ratio intercepts, and $\beta_1 \ldots \beta_d$ are the coefficients relating the the total aligned reads to the relative expression of the probe.  A test for compositional invariance for the experiment then becomes a test of the null hypothesis, $H_o: \beta_1 = \cdots = \beta_d = 0$. This test can be re-parameterized to test for dependence between the variance and total aligned reads as well.


Unfortunately, the small sample sizes and large number of probes typically associated with RNA-Seq experiments complicates the application of Aitchison's model.  
We propose an alternative visualization for simultaneously detecting both violations of compositional invariance described above. We use the multivariate Aitchison distance (\ref{aitchdist2}) between all pairs of samples in a heat-map with the samples ordered by total aligned reads.  If CI is violated we expect pairs samples with similar total aligned reads will have smaller scalar distances than those with large differences in total aligned reads.  This will result in visual clustering around the 45 degree axis. If the variance depends on the total aligned reads, we expect the scalar distance between sample pairs to decrease with increasing read depth resulting in a visual gradient in the distance heat map.  To reduce the visual noise associated with outlier samples in the heat-map we also provide a dot-plot of the distance between each CLR transformed sample and the compositional center of the samples in the top quartile of total reads.\\

We demonstrate this visualization with two sets of miRNA samples (Fig.~\ref{miComp}) and two sets of mRNA samples(Fig.~\ref{celComp}).  The miRNA samples are composed of 40 technical replicates each of (1) plasma samples and (2) brain samples.  In the miRNA data there is a clear gradient along the 45 degree axis for the plasma samples (Fig.~\ref{miComp}.A).  This indicates a dependence between the total aligned reads and the variance of the samples (as indicated by the increasing multivariate distance between replicates as the total aligned reads decreases).  In contrast, there is no clear gradient in the brain samples (Fig.~\ref{miComp}.B).  The mRNA samples are composed of (A) 16 technical replicates of diseased pancreas tissue and (B) 16 technical replicates of normal pancreas tissue.  In the diseased pancreas samples there is a clear gradient with low total aligned read samples more distant from samples with greater total aligned reads (Fig.~\ref{celComp}.1).  This indicates that the composition is dependent on the total aligned reads, a violation of compositional invariance for these samples.  In contrast, the normal pancreas samples show no such pattern related to total aligned reads (Fig.~\ref{celComp}.2).\\

\begin{figure}
\centering
\includegraphics[scale=0.6]{./Figures/CompInvPlots_miRNA}
\label{miComp}
\caption{Two sets of miRNA samples with samples in (1.) showing a violation of compositional invariance and (2) showing compositional invariance.}
\end{figure}


\begin{figure}
\centering
\includegraphics[scale=0.6]{./Figures/CompInvPlots_Celgene}
\label{celComp}
\caption{Two sets of mRNA samples with samples in (1.) showing a violation of compositional invariance and (2) showing compositional invariance.}
\end{figure}

\FloatBarrier
\section{Batch Effects and Normalization}

Batch effects arising from differing laboratory conditions or operator differences have been identified as a problem in high-throughput measurement systems~\cite{leek2010, chen2011}.  Identifying and controlling for batch effects is a critical step in the transition of RNA-Seq from the lab to the clinic.  Batch effects are typically identified with a hierarchical clustering (HC) method or principal components analysis (PCA).  For both methods, the multivariate distance between the samples is visualized, either in a biplot for PCA or a dendrogram for HC, to check for the existence of clusters of samples related to batch.
The compositional nature of RNA-Seq data has important implications for the detection of batch effects due to the incompatibility with standard measures of distance between compositions as noted above~\cite{Aitchison1986,Martin-Fernandez1998}.\\  

Principle components analysis is sensitive to differences in scale (total number of reads) among the variables, failure to remove these difference can mask potential batch effects and leave unwanted technical variation in the data.  As noted above, most normalization methods use a scaling factor calculated for each sample to re-scale the read count for each gene within the sample~\cite{Dillies2013}.  The CLR transformation can similarly be viewed as a scaling normalization (with the scale factor chosen as the inverse of the geometric mean $1/g(x)$).  Unlike other normalization methods, the CLR transformation has the added benefit of being applied at the individual sample level, not experiment wise like quantile or median normalization~\cite{Bolstad2003}, and requires no assumptions about differential expression among samples like quantile or median ratio normalization~\cite{Robinson2010,Anders2010}.  This makes it particularly well suited for the clinic where there are generally no reference samples for normalization.  Most importantly, CLR transformation allows the use of Euclidean geometry, such as Euclidean or Mahalanobis distance, so that standard PCA or HC applied to transformed samples can be interpreted in the traditional way~\cite{Aitchison2002} .\\

We demonstrate the use of the compositional biplot to detect batch effects using 120 technical replicates of three sample types: brain, plasma, and FFPE.  Samples were prepared using the EdgeSeq Whole Transcriptome miRNA assay which measures 2,280 targets including including 11 control probes and 2,269 unique miRNA probes.  All sequencing was performed on an Illumina Mi-seq$^{(tm)}$ sequencer.\\ 


We perform a PCA on log-transformed and CLR transformed data.  We then construct form-biplots of the first two principle components for each transformed data set (Fig.~\ref{rawPCA}).  The differences between the 3 samples types (brain, plasma, and FFPE) dominate the first two principle components for both data sets.  However, the CLR transformed data provides tighter clusters, relative to the distance between the clusters, than the log-transformed raw data.  There is also a single FFPE sample which is closer to the brain samples than the other samples.  It is worth noting that this sample would have been removed using our proposed quality control metric.  Since the sample type differences overwhelm the potential batch effects we performed a second PCA on only the brain samples for both transformed data sets (Fig.~\ref{rawPCAbrain}).  Both biplots exhibit clustering by batch but the CLR transformed data shows better separation between the batches.  \\

\begin{figure}
\includegraphics[scale=0.4]{./Figures/IO_PCA_2plot}
\label{rawPCA}
\caption{Principle component analysis of A) log-transformed and B) CLR-transformed read count data.  The differences between sample types is much greater than the batch effects in both transformation.  The CLR transformation results in tighter sample type clusters resulting from less variation along the first principle component. }
\end{figure}



\begin{figure}
\includegraphics[scale=0.4]{./Figures/IO_PCA_Brain_logRaw_CLR}
\label{rawPCAbrain}
\caption{Principle component analysis of only brain samples from A) log-transformed and B) CLR-transformed read count data. The batch effects are more easily identified in the CLR transformed data.}
\end{figure}



\FloatBarrier
\section{Discussion}

Our fractional read allocation metric can identify problematic samples which arise from multiple failure modes, e.g. a low quality sample or a sequencing problem.  However, it is conceivable that a sample might have an unusually low (or high) number of reads and still provide quality information.  In certain experimental designs one might be able to further evaluate these samples with a PCA biplot on the CLR transformed data. In our PCA analysis we identified a FFPE sample which would have failed our quality control and was clearly very different from the other technical replicates.  However, if this sample had remained quite similar to the other FFPE replicates this would have provided information that the sample may still be valuable.  In this way, the quality control metric and PCA biplot can be used in tandem to provide additional information about the quality of a sample.\\

The compositional invariance visualization is a logical extension of the sample quality control metric since the assumption of the sample quality control is that the total number of aligned reads is related to the proportional allocation of reads within the sample.  As noted above samples which violate the compositional invariance property may still contain valuable information.  The identification compositional invariance violations allows the investigator to account for the dependency between the total aligned reads and the relative abundance of transcripts within the samples when modelling.

The principal components analysis biplot is a well know dimension reduction visualization.  For the current data the dimension is reduced from 2,280 probes to 2 principle components.  The utility of the data reduction, including the quality of the approximation of the multivariate distance between the samples, is proportional to the amount of variance explained by these two principle components. In our data the first two principle components explain between 72 and 21 percent of the variation in the data.  The analysis with the lowest percent of variation explained by the first 2 components is of the CLR-transformed brain samples.  Surprisingly, batch effects are still visible in this plot, in which case they can be removed~\cite{Luo2010}.  \\

As RNA-Seq makes the transition from the research laboratory to the clinic there is a need for robust quality control metrics.  The realization that RNA-Seq data are compositional opens the door to the existing body of theory and methods developed by John Atichison and others.  We show that the properties of compositional data can be leveraged to develop new metrics and enhance existing methods.\\


%ask Shripad about slide 59 from his defense Re: interpretation of the biplot on the raw log-transformed data
\newpage
\printbibliography


<<Set_up, echo = FALSE, message = FALSE, eval = FALSE>>=
library(HTGPackage)
library(car)
library(tidyverse)
# library(compositions)
library(reshape2)
library(cowplot)

plotPCA <- function(data, annodata, projname, Max=80, pc1 = "PC1", pc2 = "PC2", scale = FALSE){
  x <- t(data)
  pcares <- prcomp(x, scale = scale)
  print(summary(pcares))
  pvar <- summary(pcares)$importance[3, 2]
  plot(pcares,type="l")
  pcavect<-pcares$x[,1:5]
  indanno<-intersect(row.names(pcavect),row.names(annodata))
  pcavect<-pcavect[indanno,]
  anno.pca<-annodata[indanno,]
  pcadata <- cbind(anno.pca, pcavect)
  return(list(pcadata, pvar))
}


pcaBiplot <- function(data,
                      printSum = FALSE
                      )
{
  
  #############################################################################
  #############################################################################
  ## This function conducts a PCA and prepares data for producing a biplot
  #############################################################################
  #############################################################################
  
  pcadf <- data.matrix(data)
  
  #perform PCA
  pca <- prcomp(t(pcadf), retx = TRUE)
  
  if(printSum) print(summary(pca))
  
  #Get proportion of variance explained by first 2 comps
  pvar <- summary(pca)$importance[3, 2]
  
  #-----Create biplot data for use with ggplot-----#
  nobs.factor <- sqrt(nrow(pca$x) - 1)
  d <- pca$sdev
  u <- sweep(pca$x, 2, 1/(d * nobs.factor), FUN = "*")
  v <- pca$rotation
  #select first two PCs
  df.u <- as.data.frame(sweep(u[, 1:2], 2, c(1,1), FUN = "*"))
  v <- sweep(v, 2, d, FUN = "*")
  df.v <- as.data.frame(v[, 1:2])
  names(df.u) <- c("xvar", "yvar")
  names(df.v) <- names(df.u)
  df.u <- df.u * nobs.factor
  r <- sqrt(qchisq(0.69, df = 2)) * prod(colMeans(df.u^2))^(1/4)
  v.scale <- rowSums(v^2)
  df.v <- r * df.v/sqrt(max(v.scale))
  
  df.v$angle <- with(df.v, (180/pi) * atan(yvar/xvar))
  df.v$hjust = with(df.v, (-.5 * sign(xvar))/2)
  
  return(list(df.v = df.v, df.u = df.u, pvar = pvar))
}


getPlates <- function(x){
  df <- as.data.frame(x)
  df$Proc <- gsub(".*(P\\d{2}).*", "\\1", df$Sample.Name)
  df$Day <- ifelse(grepl("D", df$Sample.Name), gsub(".*(D\\d{1}).*", "\\1", df$Sample.Name), "D1")
  df$Plate <- factor(paste0(df$Proc, "_", df$Day))
  return(df)
}

getTots <- function(x){#use t-list
  df <- as.data.frame(t(x[, -1]))
  names(df) <- make.names(x[, 1])
  df$row <- gsub("(\\w{1})\\d{1,2}$", "\\1", df$Well)
  df$column <- gsub("\\w{1}(\\d{1,2})$", "\\1", df$Well)
  df$Total.Reads <- as.numeric(as.character(df$Total.Counts))
  df <- df[which(!grepl("No_Sample", df$Sample.Name)), ]
  return(df)
}

getTots_mi <- function(x){#use t-list
  df <- as.data.frame(t(x))
  df$row <- gsub("(\\w{1})\\d{1,2}$", "\\1", df$Well)
  df$column <- gsub("\\w{1}(\\d{1,2})$", "\\1", df$Well)
  df$Total.Reads <- as.numeric(as.character(df$Total.Reads))
  df <- df[which(!grepl("No_Sample", df$Sample.Name)), ]
  return(df)
}

MFtrans <- function(x){
  delta <- 0.55/sum(x)
  tdelta <- sum(x == 0) * delta
  cx <-  x/sum(x)
  cxt <- ifelse(cx == 0, delta, cx * (1-tdelta))
  return(cxt)
}

#CLR transformation after Martin-Fernandez zero transformation
MFtrans.clr <- function(x){#apply to a vector
  cxt <- MFtrans(x)
  ccxt <- log(cxt) - sum(log(cxt))/length(cxt)
  return(ccxt)
}

#ALR transformation after Martin-Fernandez zero transformation
MFtrans.alr <- function(x, ivar){#apply to a vector
  cxt <- MFtrans(x)
  lcxt <- log(cxt)
  ccxt <- lcxt[-ivar] - lcxt[ivar]
  return(ccxt)
}


#Make the legend pretty when it is below the graph
fancy_scientific <- function(l) {
     # turn in to character string in scientific notation
     l <- format(l, scientific = TRUE)
     # quote the part before the exponent to keep all the digits
     l <- gsub("^(.*)e\\+", "'\\1'e", l)
     # turn the 'e+' into plotmath format
     l <- gsub("e", "%*%10^", l)
     # return this as an expression
     parse(text=l)
}

#Function to find the CLR outliers, returns a vector of indices for failed samples
getCLROutliers <- function(x){
  #x is a vector or sample total reads
  cx <- log(x) - mean(log(x))
  lq <- quantile(cx, prob = .25)
  uq <- quantile(cx, prob = .75)
  llim <- lq - 1.5 * (uq - lq)
  ulim <- uq + 1.5 * (uq - lq)
  fails <- which(cx < llim | cx > ulim)
  return(fails)
}

source("compInvTest.R")


load("./Data/IO_repro_data_lists.Rdata")
load("./Data/miRNA_Data_lists.Rdata")
raw.w.mi <- plyr::join_all(dflist_mi, by = "X1")
names(raw.w.mi) <- make.names(raw.w.mi[3, ])
rownames(raw.w.mi) <- make.names(raw.w.mi[, 1])
@


<<IO_Repro_Study, echo = FALSE, message = FALSE, eval = FALSE>>=

#----- Heat Maps -----#


tots <- lapply(tlist, getTots)

tots <- lapply(tots, getPlates)

#Choose P86 and ignore P02
totl <- do.call(rbind, tots)
totl <- totl[which(!grepl("P02", totl$Proc)),]

#define order of the plates for other plots
IO_repro_plates <- levels(totl$Plate)
totl$column <- factor(totl$column, levels = as.character(1:12))


totl$colCompressed <- factor(ifelse(totl$column %in% c(4,7,10), 1, 
                             ifelse(totl$column %in% c(5,8,11), 2, 3)))
totl$PlateGen <- Recode(totl$Plate, "'P86_D1' = 'Run 1'; 'P88_D1' = 'Run 2'; 'P35_D1' = 'Run 3'; 'P86_D2' = 'Run 4'; 'P86_D3' = 'Run 5'")



IOrawTotalsCompressed <- ggplot(totl, aes(x = colCompressed, y = row)) + geom_tile(aes(fill = Total.Reads)) + facet_wrap(~PlateGen, ncol = 5) + plotTheme()  +  xlab("Sample Column") + ylab("Sample Row")  + scale_fill_continuous("Total Reads", labels = fancy_scientific, guide = guide_legend(label.theme = element_text(angle = 45), label.position = "bottom", label.hjust = .5, label.vjust = .5, direction = "horizontal", keywidth = 2))
ggsave("./Figures/IO_Repro_TotalCountHeatMap_RawTotals_Compressed.png", IOrawTotalsCompressed, width = 14 , height = 5)

TotalBoxplot_IO <- ggplot(totl, aes(x = 1, y = Total.Reads)) + geom_boxplot(outlier.color = "red") + facet_wrap(~PlateGen, ncol = 5) + plotTheme(axis.text.x = element_blank(), axis.text.y = element_text(angle = 90, hjust = .5)) + xlab("")



Total_Combined_IO <- plot_grid(TotalBoxplot_IO, IOrawTotalsCompressed, labels = c("A", "B"), nrow = 2, ncol =1)
ggsave("./Figures/IO_Repro_Combined_RawTotals.png", Total_Combined_IO, width = 14 , height = 10)





#CLR the total reads
clrReads <- function(x){
   cbind(x, CLR = as.vector(clr( acomp( as.numeric(as.character(x$Total.Counts)) ), detectionlimit = 0 )))
}
# tots.clr <- lapply(tots, FUN = clrReads)
CLRTotals <- do.call(rbind, tots)
#randomly remove P02 processor
CLRTotals <- CLRTotals[which(!grepl("P02", CLRTotals$Plate)), ]
CLRTotals$Plate <- factor(CLRTotals$Plate)
#split by plate to perform clr
CLRsplit <- split(CLRTotals, CLRTotals$Plate)
#CLR transform each plate
CLRsplit <- lapply(CLRsplit, clrReads)
#re-assemble data
CLRTotals <- do.call(rbind, CLRsplit)
CLRTotals$column <- factor(CLRTotals$column, levels = 1:12)
CLRTotals$Plate <- factor(CLRTotals$Plate, levels = IO_repro_plates)

# IOCLRTots <- ggplot(CLRTotals, aes(x = column, y = row)) + geom_tile(aes(fill = CLR)) + facet_wrap(~Plate, ncol = 5) + plotTheme(legend.position = "right") +  xlab("Plate Column") + ylab("Plate Row")
# ggsave("./Figures/IO_Repro_TotalCountHeatMap_CLRTotals.png", IOCLRTots, width = 14 , height = 5)

CLRTotals$colCompressed <- factor(ifelse(CLRTotals$column %in% c(4,7,10), 1, 
                             ifelse(CLRTotals$column %in% c(5,8,11), 2, 3)))
CLRTotals$PlateGen <- Recode(CLRTotals$Plate, "'P86_D1' = 'Run 1'; 'P88_D1' = 'Run 2'; 'P35_D1' = 'Run 3'; 'P86_D2' = 'Run 4'; 'P86_D3' = 'Run 5'")

IOCLRTotsCompressed <- ggplot(CLRTotals, aes(x = colCompressed, y = row)) + geom_tile(aes(fill = CLR)) + facet_wrap(~PlateGen, ncol = 5) + plotTheme() +  xlab("Sample Column") + ylab("Sample Row") + scale_fill_continuous("CLR Transformed\nTotal Reads")
ggsave("../Paper1/Figures/IO_Repro_TotalCountHeatMap_CLRTotals_Compressed.png", IOCLRTotsCompressed, width = 14 , height = 5)

CLRBoxplot_IO <- ggplot(CLRTotals, aes(x = 1, y = CLR)) + geom_boxplot(outlier.color = "red") + facet_wrap(~PlateGen, ncol = 5) + plotTheme(axis.text.x = element_blank(), axis.text.y = element_text(angle = 90, hjust = .5))

CLR_Combined_IO <- plot_grid(CLRBoxplot_IO, IOCLRTotsCompressed, labels = c("A", "B"), nrow = 2, ncol =1)
ggsave("../Paper1/Figures/IO_Repro_Combined_CLR.png", CLR_Combined_IO, width = 14 , height = 10)

@



<<PCA_miRNA, echo = FALSE, results = 'hide', warning = FALSE, fig.keep = 'none', eval = FALSE>>=
annodf.mi <- data.frame(SampleID = names(raw.w.mi)[-1])
annodf.mi$Run <- gsub("^(run\\d{3})\\..*", "\\1", annodf.mi$SampleID)
annodf.mi$Run <- paste("Run", as.numeric(as.factor(annodf.mi$Run)))
annodf.mi$SampType <- gsub("(^run\\d{3})\\.(\\w+)\\_\\d\\_\\d$", "\\2", annodf.mi$SampleID)
rownames(annodf.mi) <- annodf.mi$SampleID

pcaDat.mi.orig <- data.matrix(raw.w.mi[-c(1:5), -c(1, 36)])

#create matrix of multipliers to change scaling of raw data
set.seed(390)
sc <- runif(ncol(pcaDat.mi.orig), .5, 1.5)
scmat <- matrix(nrow = nrow(pcaDat.mi.orig), ncol = ncol(pcaDat.mi.orig))
for(i in 1:ncol(scmat)){
  scmat[, i] <- sc[i]
}

#Shift the location of every sample by the same amount
prt <- runif(nrow(pcaDat.mi.orig))
prt <- prt/sum(prt)



pcaDat.mi.p <- pcaDat.mi.orig
#Randomly scale raw data
# pcaDat.mi <- scmat * pcaDat.mi


#perturb raw data the same amount for every sample
for( i in 1:ncol(pcaDat.mi.p)){
  #first close each sample
  pcaDat.mi.p[, i] <- pcaDat.mi.p[, i]/sum(pcaDat.mi.p[, i])
  #apply the perturbation
  pcaDat.mi.p[, i] <- (pcaDat.mi.p[, i] * prt)
  #Reclose the data
  pcaDat.mi.p[, i] <- pcaDat.mi.p[, i]/sum(pcaDat.mi.p[, i])
}

###############################################################################
###############################################################################
#First perform PCA on log-transformed data
###############################################################################
###############################################################################

#log transform
logdat <- apply(pcaDat.mi.orig[-c(1:11), ], c(1,2), function(x) log2(x + 1))

#perform PCA
pcalogdat <- pcaBiplot(logdat)

pcalogdat$df.u$SampleID <- rownames(pcalogdat$df.u)
pcalogdat$df.u <- merge(pcalogdat$df.u, annodf.mi, by = "SampleID")

#biplot of the PCA for log-raw data
logdatPCA <- ggplot(pcalogdat$df.u, aes(x = xvar, y = yvar, color = Run, shape = SampType)) +
  geom_point( size = 3)  +
  coord_equal() + 
  xlab("PC1") +
  ylab("PC2") +
  ggtitle(paste0("Cum. proportion of var. = ", round(pcalogdat$pvar, 2))) +
  scale_shape_discrete("Sample Type")
ggsave("./Figures/miRNA_Repro_PCA_log(raw).png", ggpcal.mi.l, width = 9, height = 8 )

#Only Brain
logdat.brain <- logdat[, which(grepl("Brain", colnames(logdat)))]

pcalogdat.brain <- pcaBiplot(logdat.brain)
pcalogdat.brain$df.u$SampleID <- rownames(pcalogdat.brain$df.u)
pcalogdat.brain$df.u <- merge(pcalogdat.brain$df.u, annodf.mi, by = "SampleID")

logdatPCA.brain <- ggplot(pcalogdat.brain$df.u, aes(x = xvar, y = yvar, color = Run)) + 
    geom_point( size = 3) +
      ylab("PC2") +
      xlab("PC1") +
    coord_equal() + #ylim(c(-30, 100)) + xlim(c(-50, 160)) +
  ggtitle(paste0("Cum. proportion of var. = ", round(pcalogdat.brain$pvar, 2)))
ggsave("./Figures/miRNA_Repro_PCA_log(raw)_BrainOnly.png", logdatPCA.brain, width = 9, height = 8 )


###############################################################################
#Perform PCA on the perturbed data after log transformation
###############################################################################

logdat.p <- apply(pcaDat.mi.p[-c(1:11), ], c(1,2), function(x) log2(x*10e6 + 1))


pcalogdat.p <- pcaBiplot(logdat.p)

pcalogdat.p$df.u$SampleID <- rownames(pcalogdat.p$df.u)
pcalogdat.p$df.u <- merge(pcalogdat.p$df.u, annodf.mi, by = "SampleID")

#biplot of the PCA for log-raw data
logdatPCA.p <- ggplot(pcalogdat.p$df.u, aes(x = xvar, y = yvar, color = Run, shape = SampType)) +
  geom_point( size = 3)  +
  coord_equal() + 
  xlab("PC1") +
  ylab("PC2") +
  ggtitle(paste0("Cum. proportion of var. = ", round(pcalogdat.p$pvar, 2))) +
  scale_shape_discrete("Sample Type")
ggsave("./Figures/miRNA_Repro_PCA_log(raw).png", ggpcal.mi.l, width = 9, height = 8 )


logdat.p.brain <- logdat.p[, which(grepl("Brain", colnames(logdat.p)))]
pcalogdat.p.brain <- pcaBiplot(logdat.p.brain)
pcalogdat.p.brain$df.u$SampleID <- rownames(pcalogdat.p.brain$df.u)
pcalogdat.p.brain$df.u <- merge(pcalogdat.p.brain$df.u, annodf.mi, by = "SampleID")

logdatPCA.brain.p <- ggplot(pcalogdat.p.brain$df.u, aes(x = xvar, y = yvar, color = Run)) + 
  geom_point( size = 3) +
  ylab("PC2") +
  xlab("PC1" ) +
  coord_equal() + #ylim(c(-30, 100)) + xlim(c(-50, 160)) +
  ggtitle(paste0("Cum. proportion of var. = ", round(pcalogdat.p.brain$pvar, 2)))
ggsave("./Figures/miRNA_Repro_PCA_log(raw)_BrainOnly_perturbed.png", ggpcal.mi.l.brain, width = 9, height = 8 )


###############################################################################
# Perform PCA on CLR data
###############################################################################


clrdat <- pcaDat.mi.orig[-c(1:11), -35]

clrdat <- as.data.frame(apply(clrdat, 2, MFtrans.clr))

pcaclrdat <- pcaBiplot(clrdat)
pcaclrdat$df.u$SampleID <- rownames(pcaclrdat$df.u)
pcaclrdat$df.u <- merge(pcaclrdat$df.u, annodf.mi, by = "SampleID")

clrdatPCA <- ggplot(pcaclrdat$df.u, aes(x= xvar, y= yvar, color=Run, shape = SampType)) +
  geom_point( size = 3)   +
  coord_equal()  +
  xlab("PC1") +
  ylab("PC2") +
  ggtitle(paste0("Cum. proportion of var. = ", round(pcaclrdat$pvar, 2))) +
  scale_shape_discrete("Sample Type")

ggsave("./Figures/miRNA_Repro_PCA_CLR_BrainOnly.png", clrdatPCA, width = 9, height = 8 )



clrdat.brain <- pcaDat.mi.orig[-c(1:11), which(grepl("Brain", colnames(pcaDat.mi.orig)))]

clrdat.brain <- as.data.frame(apply(clrdat.brain, 2, MFtrans.clr))

pcaclrdat.brain <- pcaBiplot(clrdat.brain)
pcaclrdat.brain$df.u$SampleID <- rownames(pcaclrdat.brain$df.u)
pcaclrdat.brain$df.u <- merge(pcaclrdat.brain$df.u, annodf.mi, by = "SampleID")

clrdatPCA.brain <- ggplot(pcaclrdat.brain$df.u, aes(x= xvar, y= yvar, color=Run)) +
  geom_point( size = 3)   +
  coord_equal()  +
  xlab("PC1") +
  ylab("PC2") +
  ggtitle(paste0("Cum. proportion of var. = ", round(pcaclrdat.brain$pvar, 2)))

ggsave("./Figures/miRNA_Repro_PCA_CLR_BrainOnly.png", ggpcac.brain, width = 9, height = 8 )

###############################################################################
#CLR of perturbed data
###############################################################################

clrdat.p <- pcaDat.mi.p[-c(1:11), -35]*10e6

clrdat.p <- as.data.frame(apply(clrdat.p, 2, MFtrans.clr))

pcaclrdat.p <- pcaBiplot(clrdat.p)
pcaclrdat.p$df.u$SampleID <- rownames(pcaclrdat.p$df.u)
pcaclrdat.p$df.u <- merge(pcaclrdat.p$df.u, annodf.mi, by = "SampleID")

clrdatPCA.p <- ggplot(pcaclrdat.p$df.u, aes(x= xvar, y= yvar, color=Run)) +
  geom_point( size = 3)   +
  coord_equal()  +
  xlab("PC1") +
  ylab("PC2") +
  ggtitle(paste0("Cum. proportion of var. = ", round(pcaclrdat.p$pvar, 2)))

ggsave("./Figures/miRNA_Repro_PCA_CLR_BrainOnly.png", ggpcac.brain, width = 9, height = 8 )


clrdat.p.brain <- apply(pcaDat.mi.p[-c(1:11), which(grepl("Brain", colnames(pcaDat.mi.p)))]*10e6,
                        2,
                        MFtrans.clr) %>%
  as.data.frame()

pcaclrdat.p.brain <- pcaBiplot(clrdat.p.brain)
pcaclrdat.p.brain$df.u$SampleID <- rownames(pcaclrdat.p.brain$df.u)
pcaclrdat.p.brain$df.u <- merge(pcaclrdat.p.brain$df.u, annodf.mi, by = "SampleID")

clrdatPCA.brain <- ggplot(pcaclrdat.p.brain$df.u, aes(x= xvar, y= yvar, color=Run)) +
  geom_point( size = 3)   +
  coord_equal()  +
  xlab("PC1") +
  ylab("PC2") +
  ggtitle(paste0("Cum. proportion of var. = ", round(pcaclrdat.p.brain$pvar, 2)))
ggsave("./Figures/miRNA_Repro_PCA_CLR.png", ggpcac, width = 9, height = 8 )

##Check for distance between perturbed and unperturbed points
pert <- pcaclrdat.p.brain$df.u
unpert <- pcaclrdat.brain$df.u

hyp <- function(x, y){
  return(sqrt((x[1] - y[1])^2 + (x[2] - y[2])^2 ))
}

hyp(x = unpert[1, 2:3], y = unpert[2, 2:3])

####################################################

pcaDatc.mi.brain.p <- pcaDatc.mi.p[, which(grepl("Brain", colnames(pcaDatc.mi.p)))]
pcplotdatc.mi.brain.p <- plotPCA(pcaDatc.mi.brain.p, annodf.mi, scale = FALSE)
ggpcac.brain <- ggplot(pcplotdatc.mi.brain.p[[1]], aes(x= PC1, y= PC2, color=Run, label = SampleID)) +
    geom_point( size = 3)   +
    coord_equal() +
    ggtitle(paste0("Cum. proportion of var. = ", round(pcplotdatc.mi.brain[[2]], 2)))
ggsave("./Figures/miRNA_Repro_PCA_CLR_BrainOnly.png", ggpcac.brain, width = 9, height = 8 )


pcaPlots2 <- plot_grid(ggpcal.mi.l, ggpcac, ncol = 2, nrow = 1, labels = c("A", "B"))
ggsave("../Paper1/Figures/miRNA_PCA_2plot.png", pcaPlots2, height = 8, width = 16)

brainPCA <- plot_grid(ggpcal.mi.l.brain, ggpcac.brain, ncol = 2, nrow = 1, labels = c("A", "B"))
ggsave("../Paper1/Figures/miRNA_PCA_Brain_logRaw_CLR_perturbed.png", brainPCA, height = 8, width = 16)


brainPCAperturbed <- plot_grid(ggpcal.mi.l.brain.perturbed, ggpcac.brain, ncol = 2, nrow = 1, labels = c("A", "B"))
ggsave("../Paper1/Figures/miRNA_PCA_Brain_logRaw_CLR_perturbed.png", brainPCAperturbed, height = 8, width = 16)



#CPM transformed raw data
brainCPM <- cpmStand(pcaDat.mi.orig[-c(1:11), which(grepl("Brain", colnames(pcaDat.mi.orig)))])

brainCPMpca <- pcaBiplot(brainCPM)
brainCPMpca$df.u$SampleID <- rownames(brainCPMpca$df.u)
brainCPMpca$df.u <- merge(brainCPMpca$df.u, annodf.mi, by = "SampleID")

ggpcac.brain <- ggplot(brainCPMpca$df.u, aes(x= xvar, y= yvar, color=Run)) +
  geom_point( size = 3)   +
  coord_equal()  +
  xlab("PC1") +
  ylab("PC2") +
  ggtitle(paste0("Cum. proportion of var. = ", round(brainCPMpca$pvar, 2)))
ggsave("./Figures/miRNA_Repro_PCA_CLR.png", ggpcac, width = 9, height = 8 )


@

<<CompositionalInvariance, echo = FALSE, eval = FALSE>>=
###############################################################################
###############################################################################
## Use available data sets to demonstrate compositional invariance
###############################################################################
###############################################################################

#Create compositional invariance annotation for mi-RNA data
CIanno <- data.frame(sample = names(raw.w.mi)[-1],
                     total = as.numeric(raw.w.mi["Total.Reads", -1]),
                     Run = gsub("^(run\\d{3})\\..*", 
                                "\\1", 
                                names(raw.w.mi)[-1]),
                     SampType = gsub("(^run\\d{3})\\.(\\w+)\\_\\d\\_\\d$",
                                     "\\2", 
                                     names(raw.w.mi)[-1]),
                     stringsAsFactors = FALSE)

#Find low-read outliers and remove
failInd <- getCLROutliers(CIanno$total)

CIanno <- CIanno[, -failInd]

miraw <- data.matrix(raw.w.mi[-c(1:5), -1])

miraw <- miraw[, -failInd]

#Create clr transformed data using MF and CLR
miclr <- apply(miraw, 2, MFtrans.clr) %>%
  as.data.frame()

###############################################################################
###############################################################################
## This section uses the traditional Aitchison model to find compositional 
## invariance
###############################################################################
###############################################################################


mitestdf <- miraw %>%
  as.data.frame() %>%
  mutate(probe = rownames(miraw))

#rearrange data to have probe first
mitestdf <- mitestdf[, c(ncol(mitestdf), 1:(ncol(mitestdf)-1))]

##Find which probe for denominator
ivar <- mitestdf %>%
  gather(sample, count, 2:ncol(mitestdf)) %>%
  group_by(probe) %>%
  summarize(avg = mean(count))

ivars <- ivar$probe[which(ivar$avg >  quantile(ivar$avg, prob = .49) & ivar$avg < quantile(ivar$avg, prob = .51))]
    


mialr.plasma.test <- compInvTest(data = mitestdf[, c("probe", names(mitestdf)[which(grepl("Plasma", names(mitestdf)))])],
                          trans = "alr")

ggplot(mialr.plasma.test$betas, aes(x = est)) + 
  geom_density() + 
  annotate("text", 
           x = -2, 
           y = 0.5, 
           label =  paste0(sum(mialr.plasma.test$betas$adjP < 0.05), " adj P < 0.05")) +
  xlab("Estimate of Beta")



mialr.brain.test <- compInvTest(data = mitestdf[, c("probe", names(mitestdf)[which(grepl("Brain", names(mitestdf)))])],
                          trans = "clr")

ggplot(mialr.brain.test$betas, aes(x = est)) + 
  geom_density() + 
  annotate("text", 
           x = -1, 
           y = 0.75, 
           label =  paste0(sum(mialr.brain.test$betas$adjP < 0.05), " adj P < 0.05")) +
  annotate("text", 
           x = -1, 
           y = 0.55, 
           label =  paste0(sum(mialr.brain.test$betas$pval < 0.05, na.rm = TRUE), " P < 0.05")) +
  xlab("Estimate of Beta")


mialr.ffpe.test <- compInvTest(data = mitestdf[, c("probe", names(mitestdf)[which(grepl("FFPE", names(mitestdf)))])],
                          trans = "clr")

ggplot(mialr.ffpe.test$betas, aes(x = as.numeric(as.character(est)))) + 
  geom_density()


mialr.test$numSig

#repeat with only plasma samples
mitestplas <- miraw[, which(grepl("Plasma", colnames(miraw)))] %>%
  as.data.frame() %>%
  mutate(probe = rownames(miraw))

mitestplas <- mitestplas[, c(ncol(mitestplas), 1:(ncol(mitestplas)-1))]

for(i in 1:length(ivars)){
mialr.test.plas <- compInvTest(data = mitestplas,
                          trans = "clr",
                          ivar = ivars[i])

print(mialr.test.plas$numSig)
}

##The clr test will be affected by the number of probes that exhibit compositional
##invariance since these probes will have increasing influence on the geometric mean
## if the geometric mean changes from sample to sample more probes will exhibit CI
## ALR appears highly dependent on the choice of denominator since if the denominator 
## does not have CI then many CI probes will appear to violate CI!!!

##Of course, in low dimensions if 1 component fails to exhibit CI, then other probes will
## also fail to exhibit CI because of the dependency. However, in the high dimensional 
## setting the change in 1 probe may be spread out over many other probes which may 
# not therefore show any violation of the CI principle.  For this reason it may be mportant
# to identify probes which violate CI individually.



#repeat with only brain samples
mitestbrain <- miraw[, which(grepl("Brain", colnames(miraw)))] %>%
  as.data.frame() %>%
  mutate(probe = rownames(miraw))

mitestbrain <- mitestbrain[, c(ncol(mitestbrain), 1:(ncol(mitestbrain)-1))]

for(i in 1:length(ivars)){
mialr.test.brain <- compInvTest(data = mitestbrain,
                          trans = "clr", 
                          ivar = ivars[i])

print(mialr.test.brain$numSig)
}

###############################################################################
###############################################################################
## This is the 'heatmap' method of visualizing compositional invariance
## The idea is that we can simultaneously evaluate both "linear invariance" as
## in the traditional Aitchison model as well as the "variance invariance" idea
## I put forth in this paper.
###############################################################################
###############################################################################


#find the distance between all pairwise samples using euclidean distance
mid <- stats::dist(t(miclr), method = "euclidean") %>%
  as.matrix()

#Set the order of the samples based on total read count
CIanno <- CIanno[order(CIanno$Run), ]
CIanno <- CIanno[order(CIanno$total), ]
CIanno <- CIanno[order(CIanno$SampType), ]
rownames(CIanno) <- CIanno$sample

miorder <- CIanno$sample

midl <- mid %>%
  as.data.frame() %>%
  mutate(row.sample = rownames(mid)) %>%
  gather(col.sample, distance, 1:ncol(mid))

midl$row.sample <- factor(midl$row.sample, levels = miorder)
midl$col.sample <- factor(midl$col.sample, levels = miorder)

#Find the maximum distance for plotting
mdist <- max(midl$distance)

#Add the total reads along the diagonal
midltots <- midl[which(midl$distance == 0) ,] 
midltots$total <- CIanno[midltots$row.sample, ]$total

#Make the heatmap with samples ordered based on total reads
miRNA.heat <- ggplot(midl, aes(x = col.sample, y = row.sample)) + 
  geom_tile(aes(fill = distance)) + 
  geom_tile(data = midltots, 
            aes(color = log(total)), 
            fill = "lightgrey",
            lwd = 1) +
  scale_fill_gradient("Distance", 
                      na.value = "lightgrey") +
  scale_color_gradientn("Total Reads", 
                        colors = c("red", "orange", "white")) +
  xlab("Sample Ordered by Type and Read Depth") + 
  ylab("Sample Ordered by Type and Read Depth") + 
  plotTheme(axis.text.x = element_blank(),
            axis.text.y = element_blank())

ggsave("./Figures/Distance_Heatmap_miRNA.png", 
       miRNA.heat, 
       height = 6, 
       width = 6)

#look at just plasma samples
midl.plasma <- midl[which(grepl("Plasma", midl$row.sample) &
                            grepl("Plasma", midl$col.sample)), ]
midl.plasma$row.sample <- factor(midl.plasma$row.sample, 
                                 levels = miorder[which(grepl("Plasma", miorder))])
midl.plasma$col.sample <- factor(midl.plasma$col.sample, 
                                 levels = miorder[which(grepl("Plasma", miorder))])

#Add the total reads along the diagonal
midltots.plas <- midl.plasma[which(midl.plasma$distance == 0 ) ,] 
midltots.plas$total <- CIanno[midltots.plas$row.sample, ]$total

plasma.mi.heat <- ggplot(midl.plasma, aes(x = col.sample, y = row.sample)) + 
  geom_tile(aes(fill = distance)) + 
  geom_tile(data = midltots.plas, 
            aes(color = log(total)), 
            fill = "lightgrey", 
            lwd = 1) +
  scale_fill_gradient("Distance", na.value = "lightgrey", limits = c(0, 95)) +
  scale_color_gradientn("log Total Reads", colors = c("red", "orange", "white"), 
                        limits = c(12, 16)) +
  xlab("Sample Ordered by Total Reads") + 
  ylab("Sample Ordered by Total Reads") +
  plotTheme(axis.text.x = element_blank(),
            axis.text.y = element_blank())

ggsave("./Figures/Distance_Heatmap_miPlasma.png", 
       plasma.mi.heat, 
       height = 6, 
       width = 6)

###############################################################################
## Brain samples for comparison with plasma samples
###############################################################################
midl.brain <- midl[which(grepl("Brain", midl$row.sample) &
                            grepl("Brain", midl$col.sample)), ]
midl.brain$row.sample <- factor(midl.brain$row.sample, 
                                 levels = miorder[which(grepl("Brain", miorder))])
midl.brain$col.sample <- factor(midl.brain$col.sample, 
                                 levels = miorder[which(grepl("Brain", miorder))])

#Add the total reads along the diagonal
midltots.brai <- midl.brain[which(midl.brain$distance == 0 ) ,] 
midltots.brai$total <- CIanno[midltots.brai$row.sample, ]$total

brain.mi.heat <- ggplot(midl.brain, aes(x = col.sample, y = row.sample)) + 
  geom_tile(aes(fill = distance)) + 
  geom_tile(data = midltots.brai, 
            aes(color = log(total)), 
            fill = "lightgrey", 
            lwd = 1) +
  scale_fill_gradient("Distance", na.value = "lightgrey", limits = c(0,95)) +
  scale_color_gradientn("log Total Reads", colors = c("red", "orange", "white"),
                        limits = c(12, 16)) +
  xlab("Sample Ordered by Total Reads") + 
  ylab("Sample Ordered by Total Reads") +
  plotTheme(axis.text.x = element_blank(),
            axis.text.y = element_blank())

ggsave("./Figures/Distance_Heatmap_miBrain.png", 
       brain.mi.heat, 
       height = 6, 
       width = 6)

plasmaGrid <- plot_grid(plasma.mi.heat, brain.mi.heat, labels = c("A", "B"))
save_plot("./Figures/Plasma_Heatmap_Compare.png",
          plot = plasmaGrid, 
          nrow = 1, 
          ncol = 2, 
          base_height = 6, 
          base_width = 6)

###############################################################################
###############################################################################
## Repeat the analysis with IO samples
###############################################################################
###############################################################################

#Get the data out of the lists

allio <- do.call(cbind, dflist)
names(allio) <- allio[3,]
rownames(allio) <- allio$`Sample Name`

#Remove no sample controls and probe columns
allio <- data.matrix(allio[-c(1:4), -c(which(grepl("Sample", names(allio))))])

iofail <- getCLROutliers(colSums(allio))

#Remove failed samples
allio <- allio[, -iofail]

ioclr <- apply(allio[-c(1:9), ], 2, MFtrans.clr) %>%
  as.data.frame()

#Create annotation for IO samples
IOanno <- data.frame(sample = names(ioclr),
                     total = colSums(allio),
                     Proc = gsub(".*_(P\\d{2})_.*", 
                                "\\1", 
                                colnames(ioclr)),
                     Rep = gsub(".*_(R\\d{1,2})$",
                                "\\1",
                                colnames(ioclr)),
                     stringsAsFactors = FALSE)

#find the distance between all pairwise samples using euclidean distance
iod <- stats::dist(t(ioclr), method = "euclidean") %>%
  as.matrix()

#Set the order of the samples based on total read count
IOanno <- IOanno[order(IOanno$total), ]
# IOanno <- IOanno[order(IOanno$Proc), ]



ioorder <- IOanno$sample

iodl <- iod %>%
  as.data.frame() %>%
  mutate(row.sample = rownames(iod)) %>%
  gather(col.sample, distance, 1:ncol(iod))

iodl$row.sample <- factor(iodl$row.sample, levels = ioorder)
iodl$col.sample <- factor(iodl$col.sample, levels = ioorder)

#Find the maximum distance for plotting
iodist <- max(iodl$distance)

#Add the total reads along the diagonal
iodltots <- iodl[which(iodl$distance == 0) ,] 
iodltots$total <- IOanno[iodltots$row.sample, ]$total
iodltots$row.sample <- factor(iodltots$row.sample, levels = ioorder)
iodltots$col.sample <- factor(iodltots$col.sample, levels = ioorder)

#Plot all samples
io.heat <- ggplot(iodl, aes(x = col.sample, y = row.sample)) + 
  geom_tile(aes(fill = distance)) + 
  geom_tile(data = iodltots, 
            aes(color = log(total)), 
            fill = "lightgrey", 
            lwd = 1) +
  scale_fill_gradient("Distance", na.value = "lightgrey", limits = c(0,95)) +
  scale_color_gradientn("log Total Reads", colors = c("red", "orange", "white"),
                        limits = c(12, 16)) +
  xlab("Sample Ordered by Total Reads") + 
  ylab("Sample Ordered by Total Reads") +
  plotTheme(axis.text.x = element_blank(),
            axis.text.y = element_blank())

ggsave("./Figures/Distance_Heatmap_IO_allSamples.png", 
       io.heat, 
       height = 6, 
       width = 6)

io <- distPlot(df = allio, quant = .75)
io$p

###############################################################################
###############################################################################
## Repeat with celgene data
###############################################################################
###############################################################################

load("./Data/CelgeneData.Rdata")
rownames(raw.w) <- raw.w[, 1]
cgdf <- raw.w[, -1]
rm(raw.w)

#Create annotation for IO samples
cganno <- data.frame(sample = names(cgdf),
                     total = colSums(cgdf),
                     type = gsub("^(NP1|NP2|DP1|DP2|uRNA).*", 
                                "\\1", 
                                names(cgdf)),
                     Rep = gsub("^(NP1|NP2|DP1|DP2|uRNA).*_(\\d{1})$",
                                "\\2",
                                names(cgdf)),
                     stringsAsFactors = FALSE)

cgclr <- apply(cgdf, 2, MFtrans.clr) %>%
  as.data.frame()

#find the distance between all pairwise samples using euclidean distance
cgd <- stats::dist(t(cgclr), method = "euclidean") %>%
  as.matrix()

#Set the order of the samples based on total read count
cganno <- cganno[order(cganno$total), ]
cganno <- cganno[order(cganno$type), ]


cgorder <- cganno$sample

cgdl <- cgd %>%
  as.data.frame() %>%
  mutate(row.sample = rownames(cgd)) %>%
  gather(col.sample, distance, 1:ncol(cgd))

cgdl$row.sample <- factor(cgdl$row.sample, levels = cgorder)
cgdl$col.sample <- factor(cgdl$col.sample, levels = cgorder)


#Add the total reads along the diagonal
cgdltots <- cgdl[which(cgdl$distance == 0) ,] 
cgdltots$total <- cganno[cgdltots$row.sample, ]$total
cgdltots$row.sample <- factor(cgdltots$row.sample, levels = cgorder)
cgdltots$col.sample <- factor(cgdltots$col.sample, levels = cgorder)

#Plot all samples
cg.heat <- ggplot(cgdl, aes(x = col.sample, y = row.sample)) + 
  geom_tile(aes(fill = distance)) + 
  geom_tile(data = cgdltots, 
            aes(color = log(total)), 
            fill = "lightgrey", 
            lwd = 1) +
  scale_fill_gradient("Distance", na.value = "lightgrey", limits = c(0,100)) +
  scale_color_gradientn("log Total Reads", colors = c("red", "orange", "white")) +#,
                        # limits = c(12, 16)) +
  xlab("Sample Ordered by Total Reads") + 
  ylab("Sample Ordered by Total Reads") +
  plotTheme(axis.text.x = element_blank(),
            axis.text.y = element_blank())

ggsave("./Figures/Distance_Heatmap_Celgene_allSamples.png", 
       cg.heat, 
       height = 6, 
       width = 6)

cg <- distPlot(df = cgdf, quant = .5)
cg$p

###############################################################################
## Only the uRNA samples
cgdl.urna <- cgdl[which(grepl("uRNA", cgdl$row.sample) &
                          grepl("uRNA", cgdl$col.sample)), ]

cgdltots.urna <- cgdltots[which(grepl("uRNA", cgdltots$row.sample) & 
                                  grepl("uRNA", cgdltots$col.sample)), ]

cg.heat.urna <- ggplot(cgdl.urna, aes(x = col.sample, y = row.sample)) + 
  geom_tile(aes(fill = distance)) + 
  geom_tile(data = cgdltots.urna, 
            aes(color = log(total)), 
            fill = "lightgrey", 
            lwd = 1) +
  scale_fill_gradient("Distance", na.value = "lightgrey", limits = c(0,100)) +
  scale_color_gradientn("log Total Reads", colors = c("red", "orange", "white"),
                        limits = c(12, 16)) +
  xlab("Sample Ordered by Total Reads") + 
  ylab("Sample Ordered by Total Reads") +
  plotTheme(axis.text.x = element_blank(),
            axis.text.y = element_blank())

ggsave("./Figures/Distance_Heatmap_Celgene_uRNA.png", 
       cg.heat.urna, 
       height = 6, 
       width = 6)
cg.urna <- distPlot(cgdf[, which(grepl("uRNA", names(cgdf)))], quant = .5)
cg.urna$p

###############################################################################
## Only the DP2 samples
cgdl.dp2 <- cgdl[which(grepl("DP2", cgdl$row.sample) &
                          grepl("DP2", cgdl$col.sample)), ]

cgdltots.dp2 <- cgdltots[which(grepl("DP2", cgdltots$row.sample) & 
                                  grepl("DP2", cgdltots$col.sample)), ]

cg.heat.dp2 <- ggplot(cgdl.dp2, aes(x = col.sample, y = row.sample)) + 
  geom_tile(aes(fill = distance)) + 
  geom_tile(data = cgdltots.dp2, 
            aes(color = log(total)), 
            fill = "lightgrey", 
            lwd = 1) +
  scale_fill_gradient("Distance", na.value = "lightgrey", limits = c(0,100)) +
  scale_color_gradientn("log(Total Reads)", colors = c("red", "orange", "white"),
                        limits = c(12, 16)) +
  xlab("Sample Ordered by Total Reads") + 
  ylab("Sample Ordered by Total Reads") +
  plotTheme(axis.text.x = element_blank(),
            axis.text.y = element_blank())

ggsave("./Figures/Distance_Heatmap_Celgene_DP2.png", 
       cg.heat.dp2, 
       height = 6, 
       width = 6)

cgGrid <- plot_grid(cg.heat.urna, cg.heat.dp2, labels = c("A", "B"))
save_plot("./Figures/CG_Heatmap_compare.png", 
          plot = cgGrid, 
          nrow = 1, 
          ncol = 2, 
          base_height = 6, 
          base_width = 6)


#####################################################################
#####################################################################
### Find the center of the top quartile of samples with respect to 
### total reads
#####################################################################
#####################################################################
heatPlot <- function(df){
  #Create annotation for  samples
  anno <- data.frame(sample = names(df),
                     total = colSums(df),
                     stringsAsFactors = FALSE)
  #Set the order of the samples based on total read count
  anno <- anno[order(anno$total), ]

  clrdf <- apply(df, 2, MFtrans.clr) %>%
    as.data.frame()
  
  #find the distance between all pairwise samples using euclidean distance
  d <- stats::dist(t(clrdf), method = "euclidean") %>%
    as.matrix()
  
  #set the order of samples
  dforder <- anno$sample

  dl <- d %>%
    as.data.frame() %>%
    mutate(row.sample = rownames(d)) %>%
    gather(col.sample, distance, 1:ncol(d))

  dl$row.sample <- factor(dl$row.sample, levels = dforder)
  dl$col.sample <- factor(dl$col.sample, levels = dforder)


  #Add the total reads along the diagonal
  dltots <- dl[which(dl$distance == 0) ,] 
  dltots$total <- anno[dltots$row.sample, ]$total
  dltots$row.sample <- factor(dltots$row.sample, levels = dforder)
  dltots$col.sample <- factor(dltots$col.sample, levels = dforder)
  
  #Plot pairwise distance between all samples
  heat <- ggplot(dl, aes(x = col.sample, y = row.sample)) + 
    geom_tile(aes(fill = distance)) + 
    geom_tile(data = dltots, 
              aes(color = log(total)), 
              fill = "lightgrey", 
              lwd = 1) +
    scale_fill_gradient("Distance", 
                        na.value = "lightgrey", 
                        limits = c(0,100), 
                        guide = guide_colorbar(title.position = "top",
                                               label.theme = element_text(angle = 90))) +
    scale_color_gradientn("log(Total Reads)", 
                          colors = c("red", "orange", "yellow"), 
                        guide = guide_colorbar(title.position = "top",
                                               label.theme = element_text(angle = 90))) +
    xlab("Sample ordered by total reads") + 
    ylab("Sample ordered by total reads") +
    plotTheme(axis.text.x = element_blank(),
              axis.text.y = element_blank())
  
  return(list(p = heat, df = dl))
}

distPlot <- function(df, quant){
  ##This function takes in a data frame with samples as columns
  ## and generates a plot showing the distance between each sample
  ## and the mean of the top quant samples
  totals <- apply(df, 2, sum)
  qt <- quantile(totals, prob = quant)
  
  dfclr <- apply(df, 2, MFtrans.clr) %>%
    as.data.frame()
  
  cent <- apply(dfclr[, which(totals > quant)], 1, mean)
  distances <- apply(t(dfclr), 1, function(x) dist(rbind(x, cent)))
  
  distdf <- data.frame(SampleID = names(distances),
                       distance = distances,
                       total = as.numeric(totals),
                       inMean = ifelse(totals > qt, TRUE, FALSE))
  
  
  distdf$SampleID <- factor(distdf$SampleID, 
                         levels = names(totals)[order(totals)])
  
  p <- ggplot(distdf, aes(x = SampleID, y = distance)) +
    geom_point(aes(size = log(total), color = log(total))) +
    plotTheme(axis.text.x = element_blank()) +
    ylab(paste0("Distance between sample and center\nof top ", 
                100*(1-quant), "% high reads samples" )) +
    xlab("Samples ordered by total aligned reads") +
    scale_size_continuous("log(Total Reads)",
                          guide = guide_legend(title.position = "top")) +
    scale_color_gradientn("log(Total Reads)", 
                          colors = c("red", "orange", "yellow"),
                           guide = guide_legend(title.position = "top"))
  
  return(list(p = p, df = distdf))
}

#miRna samples
plas.mi.heat <- heatPlot(df = as.data.frame(miraw[, which(grepl("Plasma", colnames(miraw)))]))
plas <- distPlot(df = as.data.frame(miraw[, which(grepl("Plasma", colnames(miraw)))]), quant = .75)
plas$p

plasComp <- plot_grid(plas.mi.heat$p, plas$p, labels = c("A", "B"), nrow = 1)
ggsave("./Figures/Compare_compInvPlots_Plasma.png", plasComp, width = 10, height = 5)


brain.heat <- heatPlot(df = as.data.frame(miraw[, which(grepl("Brain", colnames(miraw)))]))
brain.heat$p
brain <- distPlot(df = as.data.frame(miraw[, which(grepl("Brain", colnames(miraw)))]), quant = .75)
brain$p

brainComp <- plot_grid(brain.heat$p, brain$p, labels = c("A", "B"), nrow = 1)
ggsave("./Figures/Compare_compInvPlots_Brain.png", brainComp, width = 10, height = 5)


ffpe.heat <- heatPlot(df = as.data.frame(miraw[, which(grepl("FFPE", colnames(miraw)))]))
ffpe.heat$p
ffpe <- distPlot(df = as.data.frame(miraw[, which(grepl("FFPE", colnames(miraw)))]), quant = .75)
ffpe$p

ffpeComp <- plot_grid(ffpe.heat$p, ffpe$p, labels = c("A", "B"), nrow = 1)
ggsave("./Figures/Compare_compInvPlots_FFPE.png", ffpeComp, width = 10, height = 5)

#place plasma and ffpe samples into same 4x4 plot
miRNAcomp <- plot_grid(plas.mi.heat$p, 
                       plas$p,
                       brain.heat$p, 
                       brain$p, 
                       labels = c("1a", "1b", "2a", "2b"), 
                       nrow = 2)
ggsave("./Figures/CompInvPlots_miRNA.png", miRNAcomp, width = 10, height = 10)

#Celgene samples
cgdp.heat <- heatPlot(df = cgdf[, which(grepl("DP", names(cgdf)))])
cg.dp2 <- distPlot(cgdf[, which(grepl("DP", names(cgdf)))], quant = .75)
cg.dp2$p

cgdpComp <-  plot_grid(cgdp.heat$p, cg.dp2$p, labels = c("A", "B"), nrow = 1)
ggsave("./Figures/Compare_compInvPlots_CelgeneDP.png", cgdpComp, width = 10, height = 5)

cgnp.heat <- heatPlot(df = cgdf[, which(grepl("NP", names(cgdf)))])
cgnp <- distPlot(df = cgdf[, which(grepl("NP", names(cgdf)))], quant = .75)
cgnp$p

cgnpComp <-  plot_grid(cgnp.heat$p, cgnp$p, labels = c("A", "B"), nrow = 1)
ggsave("./Figures/Compare_compInvPlots_CelgeneNP.png", cgnpComp, width = 10, height = 5)

#Put all compositional invariance plots for Celgene into single plot
dpnpComp <- plot_grid(cgdp.heat$p, 
                      cg.dp2$p,
                      cgnp.heat$p, 
                      cgnp$p, 
                      nrow = 2, 
                      labels = c("1a", "1b", "2a", "2b"))
ggsave("./Figures/CompInvPlots_Celgene.png", dpnpComp, width = 10, height = 10)

###Check that the results are not driven by specific samples
cgnp2.heat <- heatPlot(df = cgdf[, which(grepl("NP2", names(cgdf)))])
cgnp2 <- distPlot(df = cgdf[, which(grepl("NP2", names(cgdf)))], quant = .75)
cgnp2$p

cgnp2Comp <-  plot_grid(cgnp2.heat$p, cgnp2$p, labels = c("A", "B"), nrow = 1)
ggsave("./Figures/Compare_compInvPlots_CelgeneNP2.png", cgnp2Comp, width = 10, height = 5)

cgnp1.heat <- heatPlot(df = cgdf[, which(grepl("NP1", names(cgdf)))])
cgnp1 <- distPlot(df = cgdf[, which(grepl("NP1", names(cgdf)))], quant = .75)
cgnp1$p

cgnp1Comp <-  plot_grid(cgnp1.heat$p, cgnp1$p, labels = c("A", "B"), nrow = 1)
ggsave("./Figures/Compare_compInvPlots_CelgeneNP1.png", cgnp2Comp, width = 10, height = 5)

cgu.heat <- heatPlot(df = cgdf[, which(grepl("uRNA", names(cgdf)))])
cgu <- distPlot(df = cgdf[, which(grepl("uRNA", names(cgdf)))], quant = .75)

cguComp <-  plot_grid(cgu.heat$p, cgu$p, labels = c("A", "B"), nrow = 1)
ggsave("./Figures/Compare_compInvPlots_CelgeneuRNA.png", cguComp, width = 10, height = 5)


##IO samples
io.heat <- heatPlot(df = as.data.frame(allio))
io.dist <- distPlot(df = as.data.frame(allio), quant = .75)

ioComp <- plot_grid(io.heat$p, io.dist$p, labels = c("A", "B"), nrow = 1)
ggsave("./Figures/Compare_compInvPlots_IO.png", ioComp, width = 10, height = 5)

#####################################################################
#####################################################################
#####################################################################
#Trying to make the plot with ggvis so I can have two fill scales
#almost there, I just need to figure out how to set different 
#colors on the scales
ggvisMIplot <- midl.plasma %>%
  ggvis(~row.sample, ~col.sample) %>%
  layer_rects(prop("fill", ~distance,
                   scale = "distance"),
              width = band(), 
              height = band(),
              strokeWidth := 0) %>%
  layer_rects(prop("fill", ~log(total), 
                   scale = "total"),
              data = midltots.plas) %>%
  scale_nominal("x", padding = 0, points = FALSE) %>%
  scale_nominal("y", padding = 0, points = FALSE) %>%
  add_legend(scales = "distance",
             title = "Distance") %>%
  add_legend(scales = "total", 
             properties = legend_props(legend = list(y = 50)),
             title = "Log(total)" )



@




\end{document}